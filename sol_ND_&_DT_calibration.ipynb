{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQkzm9EnkhKbZ3NEKh8a6L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/websitecreatr99/Solytics/blob/main/sol_ND_%26_DT_calibration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes"
      ],
      "metadata": {
        "id": "tuTEJZ7XX6qZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://coderzcolumn.com/tutorials/machine-learning/scikit-learn-sklearn-naive-bayes"
      ],
      "metadata": {
        "id": "zzvStrwUu_L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"table_name\": \"438284d1-fe5f-4ca8-a811-67016bedea8d\",\n",
        "    \"target_column\": \"capsule\",\n",
        "    \"model_id\": 10269,\n",
        "    \"model_name\": \"G_NB\",\n",
        "    \"modelname\": \"NaiveBayesClassifier\",\n",
        "    \"project_id\": 432,\n",
        "    \"hyperparameter\": {},\n",
        "    \"formParameters\": {\n",
        "        \"model\": {\n",
        "            \"id\": 10269,\n",
        "            \"model_name\": \"G_NB\",\n",
        "            \"model_technique\": \"NaiveBayesClassifier\",\n",
        "            \"table_name\": null,\n",
        "            \"train_table\": \"438284d1-fe5f-4ca8-a811-67016bedea8d\",\n",
        "            \"test_table\": null,\n",
        "            \"column_name\": \"\",\n",
        "            \"hypertune_data\": null,\n",
        "            \"description\": \"\",\n",
        "            \"parameters\": null,\n",
        "            \"summary_stats\": null,\n",
        "            \"saved_for_doc\": true,\n",
        "            \"external_pkl\": true,\n",
        "            \"pkl_file\": \"https://nimbusuno.s3.amazonaws.com/NimbusFileManagement/NimbusUsers/Uat/qa_team/Pkls/ModelEstimation/10269.pkl?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA4IQTSJNFWGXCY552%2F20230518%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20230518T114158Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=a062ffa4bec45a9a41586920df6ca74c67e359b068860e7cc51463a24cc3fb52\",\n",
        "            \"column_pkl_file\": null,\n",
        "            \"created\": \"2023-05-04T12:46:29.145948+05:30\",\n",
        "            \"updated\": \"2023-05-04T12:46:29.197955+05:30\",\n",
        "            \"isbigdata\": false,\n",
        "            \"model_location\": null,\n",
        "            \"library\": \"sklearn\",\n",
        "            \"target_column\": \"capsule\",\n",
        "            \"is_time_model\": false,\n",
        "            \"sas_password\": null,\n",
        "            \"sas_info\": null,\n",
        "            \"user\": 3,\n",
        "            \"username\": \"qa_team\",\n",
        "            \"project\": 432,\n",
        "            \"train_table_display_name\": \"table35\"\n",
        "        },\n",
        "        \"targetColumn\": \"capsule\",\n",
        "        \"modelTechnique\": \"NaiveBayesClassifier\",\n",
        "        \"external_pkl_value\": true\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "E_CVT4KtZcjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"table_name\": \"438284d1-fe5f-4ca8-a811-67016bedea8d\",\n",
        "    \"target_column\": \"capsule\",\n",
        "    \"model_id\": 2181,\n",
        "    \"model_name\": \"1\",\n",
        "    \"modelname\": \"NaiveBayesClassifier\",\n",
        "    \"project_id\": 432,\n",
        "    \"hyperparameter\": {\n",
        "        \"var_smoothing\": [\n",
        "            4,\n",
        "            10\n",
        "        ],\n",
        "        \"Best Parameters\": {\n",
        "            \"var_smoothing\": 5\n",
        "        }\n",
        "    },\n",
        "    \"formParameters\": {\n",
        "        \"model\": {\n",
        "            \"id\": 2181,\n",
        "            \"model_name\": \"1\",\n",
        "            \"model_technique\": \"NaiveBayesClassifier\",\n",
        "            \"table_name\": \"ad9b14b8-d587-4718-ad16-9183671dd27b\",\n",
        "            \"train_table\": \"ad9b14b8-d587-4718-ad16-9183671dd27b_train_51c051\",\n",
        "            \"test_table\": \"ad9b14b8-d587-4718-ad16-9183671dd27b_test_51c051\",\n",
        "            \"column_name\": \"capsule\",\n",
        "            \"hypertune_data\": {\n",
        "                \"user\": \"qa_team\",\n",
        "                \"sampling\": 69,\n",
        "                \"threshold\": 0.7,\n",
        "                \"parameters\": {\n",
        "                    \"CatboostClassifier\": {\n",
        "                        \"n_low\": 100,\n",
        "                        \"cb_low\": 0.2,\n",
        "                        \"mdl_low\": 31,\n",
        "                        \"n_upper\": 101,\n",
        "                        \"cb_upper\": 0.3,\n",
        "                        \"lr_lower\": 0.062,\n",
        "                        \"lr_upper\": 0.063,\n",
        "                        \"depth_low\": 9,\n",
        "                        \"mdl_upper\": 32,\n",
        "                        \"depth_upper\": 10\n",
        "                    },\n",
        "                    \"XGBoost_Classifier\": {\n",
        "                        \"lr_up\": 0.11,\n",
        "                        \"md_up\": 9,\n",
        "                        \"nfold\": 3,\n",
        "                        \"lr_low\": 0.1,\n",
        "                        \"md_low\": 8,\n",
        "                        \"maxIter\": 20,\n",
        "                        \"maxbins\": 3,\n",
        "                        \"minIter\": 10,\n",
        "                        \"minbins\": 2,\n",
        "                        \"nest_up\": 201,\n",
        "                        \"maxDepth\": 3,\n",
        "                        \"minDepth\": 2,\n",
        "                        \"nest_low\": 200,\n",
        "                        \"colsample_bytree_up\": 0.3,\n",
        "                        \"colsample_bytree_low\": 0.2\n",
        "                    },\n",
        "                    \"ExtraTreesClassifierGini\": {\n",
        "                        \"md_up\": 9,\n",
        "                        \"nfold\": 3,\n",
        "                        \"nj_up\": 201,\n",
        "                        \"md_low\": 8,\n",
        "                        \"msl_up\": 3,\n",
        "                        \"mss_up\": 4,\n",
        "                        \"nj_low\": 200,\n",
        "                        \"maxbins\": 3,\n",
        "                        \"minbins\": 2,\n",
        "                        \"msl_low\": 2,\n",
        "                        \"mss_low\": 3,\n",
        "                        \"nest_up\": 101,\n",
        "                        \"maxDepth\": 3,\n",
        "                        \"minDepth\": 2,\n",
        "                        \"nest_low\": 100\n",
        "                    },\n",
        "                    \"RandomForestClassifierGini\": {\n",
        "                        \"md_up\": 9,\n",
        "                        \"nfold\": 3,\n",
        "                        \"nj_up\": 11,\n",
        "                        \"md_low\": 8,\n",
        "                        \"msl_up\": 3,\n",
        "                        \"mss_up\": 4,\n",
        "                        \"nj_low\": 10,\n",
        "                        \"maxbins\": 3,\n",
        "                        \"minbins\": 2,\n",
        "                        \"msl_low\": 2,\n",
        "                        \"mss_low\": 3,\n",
        "                        \"nest_up\": 101,\n",
        "                        \"maxDepth\": 3,\n",
        "                        \"maxTrees\": 3,\n",
        "                        \"minDepth\": 2,\n",
        "                        \"minTrees\": 2,\n",
        "                        \"nest_low\": 100\n",
        "                    },\n",
        "                    \"LogisticRegressionClassifier\": {\n",
        "                        \"c_up\": 101,\n",
        "                        \"c_low\": 100,\n",
        "                        \"nfold\": 2,\n",
        "                        \"maxIter\": 20,\n",
        "                        \"minIter\": 10,\n",
        "                        \"penalty\": \"l1\",\n",
        "                        \"maxregParam\": 1,\n",
        "                        \"minregParam\": 0,\n",
        "                        \"elasticNetParam\": 1\n",
        "                    },\n",
        "                    \"NaiveBayesClassifier\": {\n",
        "                        \"var_smoothing_low\": 4,\n",
        "                        \"var_smoothing_up\": 10\n",
        "                    }\n",
        "                },\n",
        "                \"project_id\": 432,\n",
        "                \"table_name\": \"ad9b14b8-d587-4718-ad16-9183671dd27b\",\n",
        "                \"column_name\": \"capsule\",\n",
        "                \"eval_metric\": \"roc_auc\",\n",
        "                \"autoSaveData\": [\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"CatboostClassifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"XGBoost_Classifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"RandomForestClassifierGini\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"LogisticRegressionClassifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"ExtraTreesClassifierGini\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"NaiveBayesClassifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    }\n",
        "                ],\n",
        "                \"formParameters\": {\n",
        "                    \"endDate\": {\n",
        "                        \"label\": \"\",\n",
        "                        \"value\": \"\"\n",
        "                    },\n",
        "                    \"sampling\": 69,\n",
        "                    \"modelType\": \"\",\n",
        "                    \"startDate\": {\n",
        "                        \"label\": \"\",\n",
        "                        \"value\": \"\"\n",
        "                    },\n",
        "                    \"threshold\": 0.7,\n",
        "                    \"parameters\": {\n",
        "                        \"LinearSVC\": {\n",
        "                            \"nfold\": 2,\n",
        "                            \"maxIter\": 20,\n",
        "                            \"minIter\": 10,\n",
        "                            \"maxregParam\": 3,\n",
        "                            \"minregParam\": 1\n",
        "                        },\n",
        "                        \"CatboostClassifier\": {\n",
        "                            \"n_low\": 100,\n",
        "                            \"cb_low\": 0.2,\n",
        "                            \"mdl_low\": 31,\n",
        "                            \"n_upper\": 101,\n",
        "                            \"cb_upper\": 0.3,\n",
        "                            \"lr_lower\": 0.062,\n",
        "                            \"lr_upper\": 0.063,\n",
        "                            \"depth_low\": 9,\n",
        "                            \"mdl_upper\": 32,\n",
        "                            \"depth_upper\": 10\n",
        "                        },\n",
        "                        \"XGBoost_Classifier\": {\n",
        "                            \"lr_up\": 0.11,\n",
        "                            \"md_up\": 9,\n",
        "                            \"nfold\": 3,\n",
        "                            \"lr_low\": 0.1,\n",
        "                            \"md_low\": 8,\n",
        "                            \"maxIter\": 20,\n",
        "                            \"maxbins\": 3,\n",
        "                            \"minIter\": 10,\n",
        "                            \"minbins\": 2,\n",
        "                            \"nest_up\": 201,\n",
        "                            \"maxDepth\": 3,\n",
        "                            \"minDepth\": 2,\n",
        "                            \"nest_low\": 200,\n",
        "                            \"colsample_bytree_up\": 0.3,\n",
        "                            \"colsample_bytree_low\": 0.2\n",
        "                        },\n",
        "                        \"ExtraTreesClassifierEntr\": {\n",
        "                            \"md_up\": 9,\n",
        "                            \"nfold\": 3,\n",
        "                            \"nj_up\": 201,\n",
        "                            \"md_low\": 8,\n",
        "                            \"msl_up\": 3,\n",
        "                            \"mss_up\": 4,\n",
        "                            \"nj_low\": 200,\n",
        "                            \"maxbins\": 3,\n",
        "                            \"minbins\": 2,\n",
        "                            \"msl_low\": 2,\n",
        "                            \"mss_low\": 3,\n",
        "                            \"nest_up\": 101,\n",
        "                            \"maxDepth\": 3,\n",
        "                            \"minDepth\": 2,\n",
        "                            \"nest_low\": 100\n",
        "                        },\n",
        "                        \"ExtraTreesClassifierGini\": {\n",
        "                            \"md_up\": 9,\n",
        "                            \"nfold\": 3,\n",
        "                            \"nj_up\": 201,\n",
        "                            \"md_low\": 8,\n",
        "                            \"msl_up\": 3,\n",
        "                            \"mss_up\": 4,\n",
        "                            \"nj_low\": 200,\n",
        "                            \"maxbins\": 3,\n",
        "                            \"minbins\": 2,\n",
        "                            \"msl_low\": 2,\n",
        "                            \"mss_low\": 3,\n",
        "                            \"nest_up\": 101,\n",
        "                            \"maxDepth\": 3,\n",
        "                            \"minDepth\": 2,\n",
        "                            \"nest_low\": 100\n",
        "                        },\n",
        "                        \"RandomForestClassifierEntr\": {\n",
        "                            \"md_up\": 9,\n",
        "                            \"nfold\": 3,\n",
        "                            \"nj_up\": 11,\n",
        "                            \"md_low\": 8,\n",
        "                            \"msl_up\": 3,\n",
        "                            \"mss_up\": 4,\n",
        "                            \"nj_low\": 10,\n",
        "                            \"maxbins\": 3,\n",
        "                            \"minbins\": 2,\n",
        "                            \"msl_low\": 2,\n",
        "                            \"mss_low\": 3,\n",
        "                            \"nest_up\": 101,\n",
        "                            \"maxDepth\": 3,\n",
        "                            \"maxTrees\": 3,\n",
        "                            \"minDepth\": 2,\n",
        "                            \"minTrees\": 2,\n",
        "                            \"nest_low\": 100\n",
        "                        },\n",
        "                        \"RandomForestClassifierGini\": {\n",
        "                            \"md_up\": 9,\n",
        "                            \"nfold\": 3,\n",
        "                            \"nj_up\": 11,\n",
        "                            \"md_low\": 8,\n",
        "                            \"msl_up\": 3,\n",
        "                            \"mss_up\": 4,\n",
        "                            \"nj_low\": 10,\n",
        "                            \"maxbins\": 3,\n",
        "                            \"minbins\": 2,\n",
        "                            \"msl_low\": 2,\n",
        "                            \"mss_low\": 3,\n",
        "                            \"nest_up\": 101,\n",
        "                            \"maxDepth\": 3,\n",
        "                            \"maxTrees\": 3,\n",
        "                            \"minDepth\": 2,\n",
        "                            \"minTrees\": 2,\n",
        "                            \"nest_low\": 100\n",
        "                        },\n",
        "                        \"LogisticRegressionClassifier\": {\n",
        "                            \"c_up\": 101,\n",
        "                            \"c_low\": 100,\n",
        "                            \"nfold\": 2,\n",
        "                            \"maxIter\": 20,\n",
        "                            \"minIter\": 10,\n",
        "                            \"penalty\": \"l1\",\n",
        "                            \"maxregParam\": 1,\n",
        "                            \"minregParam\": 0,\n",
        "                            \"elasticNetParam\": 1\n",
        "                        },\n",
        "                        \"NaiveBayesClassifier\": {\n",
        "                        \"var_smoothing_low\": 4,\n",
        "                        \"var_smoothing_up\": 10\n",
        "                        }\n",
        "                    },\n",
        "                    \"table_name\": \"\",\n",
        "                    \"column_name\": {\n",
        "                        \"label\": \"capsule\",\n",
        "                        \"value\": \"capsule\"\n",
        "                    },\n",
        "                    \"eval_metric\": {\n",
        "                        \"label\": \"roc_auc\",\n",
        "                        \"value\": \"roc_auc\"\n",
        "                    },\n",
        "                    \"exogColumns\": [],\n",
        "                    \"tsModelType\": \"univariate\",\n",
        "                    \"autoSaveData\": [\n",
        "                        {\n",
        "                            \"modelName\": \"1\",\n",
        "                            \"isAutoSave\": true,\n",
        "                            \"modelTechnique\": \"CatboostClassifier\",\n",
        "                            \"modelDescription\": \"1\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"modelName\": \"1\",\n",
        "                            \"isAutoSave\": true,\n",
        "                            \"modelTechnique\": \"XGBoost_Classifier\",\n",
        "                            \"modelDescription\": \"1\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"modelName\": \"1\",\n",
        "                            \"isAutoSave\": true,\n",
        "                            \"modelTechnique\": \"RandomForestClassifierGini\",\n",
        "                            \"modelDescription\": \"1\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"modelName\": \"1\",\n",
        "                            \"isAutoSave\": true,\n",
        "                            \"modelTechnique\": \"LogisticRegressionClassifier\",\n",
        "                            \"modelDescription\": \"1\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"modelName\": \"1\",\n",
        "                            \"isAutoSave\": true,\n",
        "                            \"modelTechnique\": \"ExtraTreesClassifierGini\",\n",
        "                            \"modelDescription\": \"1\"\n",
        "                        },\n",
        "                        {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"NaiveBayesClassifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"strength_metrics\": [\n",
        "                        {\n",
        "                            \"label\": \"Confusion Matrix\",\n",
        "                            \"value\": \"Confusion Matrix\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"Specifity & Sensitivity\",\n",
        "                            \"value\": \"Specifity & Sensitivity\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"Auc\",\n",
        "                            \"value\": \"Auc\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"Ks\",\n",
        "                            \"value\": \"Ks\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"Gain/Lift curve\",\n",
        "                            \"value\": \"gain/lift curve\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"Vif Test\",\n",
        "                            \"value\": \"Vif Test\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"train_test_split\": 0,\n",
        "                    \"modelTechniquesSC\": [\n",
        "                        {\n",
        "                            \"label\": \"CatboostClassifier\",\n",
        "                            \"value\": \"CatboostClassifier\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"XGBoost_Classifier\",\n",
        "                            \"value\": \"XGBoost_Classifier\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"RandomForestClassifierGini\",\n",
        "                            \"value\": \"RandomForestClassifierGini\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"LogisticRegressionClassifier\",\n",
        "                            \"value\": \"LogisticRegressionClassifier\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"ExtraTreesClassifierGini\",\n",
        "                            \"value\": \"ExtraTreesClassifierGini\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"NaiveBayesClassifier\",\n",
        "                            \"value\": \"NaiveBayesClassifier\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"stability_metrics\": [\n",
        "                        {\n",
        "                            \"label\": \"CSI\",\n",
        "                            \"value\": \"CSI\"\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "                \"Best Parameters\": {\n",
        "                    \"var_smoothing\": 5\n",
        "                },\n",
        "                \"strength_metrics\": [\n",
        "                    \"confusion matrix\",\n",
        "                    \"specifity & sensitivity\",\n",
        "                    \"auc\",\n",
        "                    \"ks\",\n",
        "                    \"gain/lift curve\",\n",
        "                    \"vif test\"\n",
        "                ],\n",
        "                \"train_test_split\": 0.69,\n",
        "                \"modelTechniquesSC\": [\n",
        "                    {\n",
        "                        \"label\": \"CatboostClassifier\",\n",
        "                        \"value\": \"CatboostClassifier\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"XGBoost_Classifier\",\n",
        "                        \"value\": \"XGBoost_Classifier\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"RandomForestClassifierGini\",\n",
        "                        \"value\": \"RandomForestClassifierGini\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"LogisticRegressionClassifier\",\n",
        "                        \"value\": \"LogisticRegressionClassifier\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"ExtraTreesClassifierGini\",\n",
        "                        \"value\": \"ExtraTreesClassifierGini\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"NaiveBayesClassifier\",\n",
        "                        \"value\": \"NaiveBayesClassifier\"\n",
        "                     }\n",
        "                ],\n",
        "                \"stability_metrics\": [\n",
        "                    \"csi\"\n",
        "                ]\n",
        "            },\n",
        "            \"description\": \"1\",\n",
        "            \"parameters\": {\n",
        "                \"var_smoothing\": [\n",
        "                  4,\n",
        "                  10\n",
        "                ],\n",
        "                \"Best Parameters\": {\n",
        "                    \"var_smoothing\": 5\n",
        "                }\n",
        "            },\n",
        "            \"summary_stats\": {\n",
        "                \"NaiveBayesClassifier\": {\n",
        "                    \"f1\": 0.3667,\n",
        "                    \"recall\": 0.234,\n",
        "                    \"accuracy\": 0.6807,\n",
        "                    \"precision\": 0.8462\n",
        "                }\n",
        "            },\n",
        "            \"saved_for_doc\": true,\n",
        "            \"external_pkl\": false,\n",
        "            \"pkl_file\": \"https://nimbusuno.s3.amazonaws.com/NimbusFileManagement/NimbusUsers/Uat/qa_team/Pkls/ModelEstimation/2181.pkl?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA4IQTSJNFWGXCY552%2F20230516%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20230516T061139Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=a4d3626ef884423b4723ab8a2e7393d60803c7c553f75526f33bdbefe00dfc74\",\n",
        "            \"column_pkl_file\": null,\n",
        "            \"created\": \"2023-02-10T13:25:09.769148+05:30\",\n",
        "            \"updated\": \"2023-02-10T13:25:09.803690+05:30\",\n",
        "            \"isbigdata\": false,\n",
        "            \"model_location\": null,\n",
        "            \"library\": \"sklearn\",\n",
        "            \"target_column\": \"capsule\",\n",
        "            \"is_time_model\": false,\n",
        "            \"sas_password\": null,\n",
        "            \"sas_info\": null,\n",
        "            \"user\": 3,\n",
        "            \"username\": null,\n",
        "            \"project\": 432,\n",
        "            \"train_table_display_name\": \"table467_train_51c051\"\n",
        "        },\n",
        "        \"targetColumn\": \"capsule\",\n",
        "        \"modelTechnique\": \"NaiveBayesClassifier\",\n",
        "        \"external_pkl_value\": false\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "pXky8CKjCzx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uLN_TmXD1Wyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0OG9Qs2W1Wvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o_xC0jGG1WsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eqO4tPuy1Wp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZgQefkYk1Wms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a9FP1ls_1Wjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "no0H6F441Wgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KtAv8pwV1Wdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hhj5rDJd1Wax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YSiaOHrR1WX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gcln9XE31WVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dz26N2Ho1WTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kVIQfxeI1WQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h9hM5XNo1WNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"table_name\": \"438284d1-fe5f-4ca8-a811-67016bedea8d\",\n",
        "    \"target_column\": \"capsule\",\n",
        "    \"model_id\": 2181,\n",
        "    \"model_name\": \"1\",\n",
        "    \"modelname\": \"DecisionTreeClassifier\",\n",
        "    \"project_id\": 432,\n",
        "    \"hyperparameter\": {\n",
        "        \"criterion\": [\n",
        "            \"gini\"\n",
        "        ],\n",
        "        \"splitter\": [\n",
        "            \"best\"\n",
        "        ],\n",
        "        \"max_depth\": [\n",
        "            4,\n",
        "            9\n",
        "        ],\n",
        "        \"random_state\": [\n",
        "            4,\n",
        "            9\n",
        "        ],\n",
        "        \"max_leaf_nodes\": [\n",
        "            4,\n",
        "            9\n",
        "        ],\n",
        "        \"Best Parameters\": {\n",
        "            \"criterion\": \"gini\",\n",
        "            \"splitter\": \"best\",\n",
        "            \"max_depth\": 8,\n",
        "            \"random_state\": 5,\n",
        "            \"max_leaf_nodes\": 8,\n",
        "            \"min_samples_split\": 5\n",
        "        },\n",
        "        \"min_samples_split\": [\n",
        "            4,\n",
        "            9\n",
        "        ]\n",
        "    },\n",
        "    \"formParameters\": {\n",
        "        \"model\": {\n",
        "            \"id\": 2181,\n",
        "            \"model_name\": \"1\",\n",
        "            \"model_technique\": \"DecisionTreeClassifier\",\n",
        "            \"table_name\": \"ad9b14b8-d587-4718-ad16-9183671dd27b\",\n",
        "            \"train_table\": \"ad9b14b8-d587-4718-ad16-9183671dd27b_train_51c051\",\n",
        "            \"test_table\": \"ad9b14b8-d587-4718-ad16-9183671dd27b_test_51c051\",\n",
        "            \"column_name\": \"capsule\",\n",
        "            \"hypertune_data\": {\n",
        "                \"user\": \"qa_team\",\n",
        "                \"sampling\": 69,\n",
        "                \"threshold\": 0.7,\n",
        "                \"parameters\": {\n",
        "                    \"CatboostClassifier\": {\n",
        "                        \"n_low\": 100,\n",
        "                        \"cb_low\": 0.2,\n",
        "                        \"mdl_low\": 31,\n",
        "                        \"n_upper\": 101,\n",
        "                        \"cb_upper\": 0.3,\n",
        "                        \"lr_lower\": 0.062,\n",
        "                        \"lr_upper\": 0.063,\n",
        "                        \"depth_low\": 9,\n",
        "                        \"mdl_upper\": 32,\n",
        "                        \"depth_upper\": 10\n",
        "                    },\n",
        "                    \"XGBoost_Classifier\": {\n",
        "                        \"lr_up\": 0.11,\n",
        "                        \"md_up\": 9,\n",
        "                        \"nfold\": 3,\n",
        "                        \"lr_low\": 0.1,\n",
        "                        \"md_low\": 8,\n",
        "                        \"maxIter\": 20,\n",
        "                        \"maxbins\": 3,\n",
        "                        \"minIter\": 10,\n",
        "                        \"minbins\": 2,\n",
        "                        \"nest_up\": 201,\n",
        "                        \"maxDepth\": 3,\n",
        "                        \"minDepth\": 2,\n",
        "                        \"nest_low\": 200,\n",
        "                        \"colsample_bytree_up\": 0.3,\n",
        "                        \"colsample_bytree_low\": 0.2\n",
        "                    },\n",
        "                    \"ExtraTreesClassifierGini\": {\n",
        "                        \"md_up\": 9,\n",
        "                        \"nfold\": 3,\n",
        "                        \"nj_up\": 201,\n",
        "                        \"md_low\": 8,\n",
        "                        \"msl_up\": 3,\n",
        "                        \"mss_up\": 4,\n",
        "                        \"nj_low\": 200,\n",
        "                        \"maxbins\": 3,\n",
        "                        \"minbins\": 2,\n",
        "                        \"msl_low\": 2,\n",
        "                        \"mss_low\": 3,\n",
        "                        \"nest_up\": 101,\n",
        "                        \"maxDepth\": 3,\n",
        "                        \"minDepth\": 2,\n",
        "                        \"nest_low\": 100\n",
        "                    },\n",
        "                    \"RandomForestClassifierGini\": {\n",
        "                        \"md_up\": 9,\n",
        "                        \"nfold\": 3,\n",
        "                        \"nj_up\": 11,\n",
        "                        \"md_low\": 8,\n",
        "                        \"msl_up\": 3,\n",
        "                        \"mss_up\": 4,\n",
        "                        \"nj_low\": 10,\n",
        "                        \"maxbins\": 3,\n",
        "                        \"minbins\": 2,\n",
        "                        \"msl_low\": 2,\n",
        "                        \"mss_low\": 3,\n",
        "                        \"nest_up\": 101,\n",
        "                        \"maxDepth\": 3,\n",
        "                        \"maxTrees\": 3,\n",
        "                        \"minDepth\": 2,\n",
        "                        \"minTrees\": 2,\n",
        "                        \"nest_low\": 100\n",
        "                    },\n",
        "                    \"LogisticRegressionClassifier\": {\n",
        "                        \"c_up\": 101,\n",
        "                        \"c_low\": 100,\n",
        "                        \"nfold\": 2,\n",
        "                        \"maxIter\": 20,\n",
        "                        \"minIter\": 10,\n",
        "                        \"penalty\": \"l1\",\n",
        "                        \"maxregParam\": 1,\n",
        "                        \"minregParam\": 0,\n",
        "                        \"elasticNetParam\": 1\n",
        "                    },\n",
        "                    \"NaiveBayesClassifier\": {\n",
        "                        \"var_smoothing_low\": 4,\n",
        "                        \"var_smoothing_up\": 10\n",
        "                    },\n",
        "                    \"DecisionTreeClassifier\": {\n",
        "                        \"md_up\": 9,\n",
        "                        \"md_low\": 4,\n",
        "                        \"rs_low\": 4,\n",
        "                        \"rs_up\": 9,\n",
        "                        \"mln_low\": 4,\n",
        "                        \"mln_up\": 9,\n",
        "                        \"ms_up\": 9,\n",
        "                        \"ms_low\": 4\n",
        "                    }\n",
        "                },\n",
        "                \"project_id\": 432,\n",
        "                \"table_name\": \"ad9b14b8-d587-4718-ad16-9183671dd27b\",\n",
        "                \"column_name\": \"capsule\",\n",
        "                \"eval_metric\": \"roc_auc\",\n",
        "                \"autoSaveData\": [\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"CatboostClassifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"XGBoost_Classifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"RandomForestClassifierGini\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"LogisticRegressionClassifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"ExtraTreesClassifierGini\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"NaiveBayesClassifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"DecisionTreeClassifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                    }\n",
        "                ],\n",
        "                \"formParameters\": {\n",
        "                    \"endDate\": {\n",
        "                        \"label\": \"\",\n",
        "                        \"value\": \"\"\n",
        "                    },\n",
        "                    \"sampling\": 69,\n",
        "                    \"modelType\": \"\",\n",
        "                    \"startDate\": {\n",
        "                        \"label\": \"\",\n",
        "                        \"value\": \"\"\n",
        "                    },\n",
        "                    \"threshold\": 0.7,\n",
        "                    \"parameters\": {\n",
        "                        \"LinearSVC\": {\n",
        "                            \"nfold\": 2,\n",
        "                            \"maxIter\": 20,\n",
        "                            \"minIter\": 10,\n",
        "                            \"maxregParam\": 3,\n",
        "                            \"minregParam\": 1\n",
        "                        },\n",
        "                        \"CatboostClassifier\": {\n",
        "                            \"n_low\": 100,\n",
        "                            \"cb_low\": 0.2,\n",
        "                            \"mdl_low\": 31,\n",
        "                            \"n_upper\": 101,\n",
        "                            \"cb_upper\": 0.3,\n",
        "                            \"lr_lower\": 0.062,\n",
        "                            \"lr_upper\": 0.063,\n",
        "                            \"depth_low\": 9,\n",
        "                            \"mdl_upper\": 32,\n",
        "                            \"depth_upper\": 10\n",
        "                        },\n",
        "                        \"XGBoost_Classifier\": {\n",
        "                            \"lr_up\": 0.11,\n",
        "                            \"md_up\": 9,\n",
        "                            \"nfold\": 3,\n",
        "                            \"lr_low\": 0.1,\n",
        "                            \"md_low\": 8,\n",
        "                            \"maxIter\": 20,\n",
        "                            \"maxbins\": 3,\n",
        "                            \"minIter\": 10,\n",
        "                            \"minbins\": 2,\n",
        "                            \"nest_up\": 201,\n",
        "                            \"maxDepth\": 3,\n",
        "                            \"minDepth\": 2,\n",
        "                            \"nest_low\": 200,\n",
        "                            \"colsample_bytree_up\": 0.3,\n",
        "                            \"colsample_bytree_low\": 0.2\n",
        "                        },\n",
        "                        \"ExtraTreesClassifierEntr\": {\n",
        "                            \"md_up\": 9,\n",
        "                            \"nfold\": 3,\n",
        "                            \"nj_up\": 201,\n",
        "                            \"md_low\": 8,\n",
        "                            \"msl_up\": 3,\n",
        "                            \"mss_up\": 4,\n",
        "                            \"nj_low\": 200,\n",
        "                            \"maxbins\": 3,\n",
        "                            \"minbins\": 2,\n",
        "                            \"msl_low\": 2,\n",
        "                            \"mss_low\": 3,\n",
        "                            \"nest_up\": 101,\n",
        "                            \"maxDepth\": 3,\n",
        "                            \"minDepth\": 2,\n",
        "                            \"nest_low\": 100\n",
        "                        },\n",
        "                        \"ExtraTreesClassifierGini\": {\n",
        "                            \"md_up\": 9,\n",
        "                            \"nfold\": 3,\n",
        "                            \"nj_up\": 201,\n",
        "                            \"md_low\": 8,\n",
        "                            \"msl_up\": 3,\n",
        "                            \"mss_up\": 4,\n",
        "                            \"nj_low\": 200,\n",
        "                            \"maxbins\": 3,\n",
        "                            \"minbins\": 2,\n",
        "                            \"msl_low\": 2,\n",
        "                            \"mss_low\": 3,\n",
        "                            \"nest_up\": 101,\n",
        "                            \"maxDepth\": 3,\n",
        "                            \"minDepth\": 2,\n",
        "                            \"nest_low\": 100\n",
        "                        },\n",
        "                        \"RandomForestClassifierEntr\": {\n",
        "                            \"md_up\": 9,\n",
        "                            \"nfold\": 3,\n",
        "                            \"nj_up\": 11,\n",
        "                            \"md_low\": 8,\n",
        "                            \"msl_up\": 3,\n",
        "                            \"mss_up\": 4,\n",
        "                            \"nj_low\": 10,\n",
        "                            \"maxbins\": 3,\n",
        "                            \"minbins\": 2,\n",
        "                            \"msl_low\": 2,\n",
        "                            \"mss_low\": 3,\n",
        "                            \"nest_up\": 101,\n",
        "                            \"maxDepth\": 3,\n",
        "                            \"maxTrees\": 3,\n",
        "                            \"minDepth\": 2,\n",
        "                            \"minTrees\": 2,\n",
        "                            \"nest_low\": 100\n",
        "                        },\n",
        "                        \"RandomForestClassifierGini\": {\n",
        "                            \"md_up\": 9,\n",
        "                            \"nfold\": 3,\n",
        "                            \"nj_up\": 11,\n",
        "                            \"md_low\": 8,\n",
        "                            \"msl_up\": 3,\n",
        "                            \"mss_up\": 4,\n",
        "                            \"nj_low\": 10,\n",
        "                            \"maxbins\": 3,\n",
        "                            \"minbins\": 2,\n",
        "                            \"msl_low\": 2,\n",
        "                            \"mss_low\": 3,\n",
        "                            \"nest_up\": 101,\n",
        "                            \"maxDepth\": 3,\n",
        "                            \"maxTrees\": 3,\n",
        "                            \"minDepth\": 2,\n",
        "                            \"minTrees\": 2,\n",
        "                            \"nest_low\": 100\n",
        "                        },\n",
        "                        \"LogisticRegressionClassifier\": {\n",
        "                            \"c_up\": 101,\n",
        "                            \"c_low\": 100,\n",
        "                            \"nfold\": 2,\n",
        "                            \"maxIter\": 20,\n",
        "                            \"minIter\": 10,\n",
        "                            \"penalty\": \"l1\",\n",
        "                            \"maxregParam\": 1,\n",
        "                            \"minregParam\": 0,\n",
        "                            \"elasticNetParam\": 1\n",
        "                        },\n",
        "                        \"NaiveBayesClassifier\": {\n",
        "                        \"var_smoothing_low\": 4,\n",
        "                        \"var_smoothing_up\": 10\n",
        "                        },\n",
        "                        \"DecisionTreeClassifier\": {\n",
        "                        \"md_up\": 9,\n",
        "                        \"md_low\": 4,\n",
        "                        \"rs_low\": 4,\n",
        "                        \"rs_up\": 9,\n",
        "                        \"mln_low\": 4,\n",
        "                        \"mln_up\": 9,\n",
        "                        \"ms_up\": 9,\n",
        "                        \"ms_low\": 4\n",
        "                      }\n",
        "                    },\n",
        "                    \"table_name\": \"\",\n",
        "                    \"column_name\": {\n",
        "                        \"label\": \"capsule\",\n",
        "                        \"value\": \"capsule\"\n",
        "                    },\n",
        "                    \"eval_metric\": {\n",
        "                        \"label\": \"roc_auc\",\n",
        "                        \"value\": \"roc_auc\"\n",
        "                    },\n",
        "                    \"exogColumns\": [],\n",
        "                    \"tsModelType\": \"univariate\",\n",
        "                    \"autoSaveData\": [\n",
        "                        {\n",
        "                            \"modelName\": \"1\",\n",
        "                            \"isAutoSave\": true,\n",
        "                            \"modelTechnique\": \"CatboostClassifier\",\n",
        "                            \"modelDescription\": \"1\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"modelName\": \"1\",\n",
        "                            \"isAutoSave\": true,\n",
        "                            \"modelTechnique\": \"XGBoost_Classifier\",\n",
        "                            \"modelDescription\": \"1\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"modelName\": \"1\",\n",
        "                            \"isAutoSave\": true,\n",
        "                            \"modelTechnique\": \"RandomForestClassifierGini\",\n",
        "                            \"modelDescription\": \"1\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"modelName\": \"1\",\n",
        "                            \"isAutoSave\": true,\n",
        "                            \"modelTechnique\": \"LogisticRegressionClassifier\",\n",
        "                            \"modelDescription\": \"1\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"modelName\": \"1\",\n",
        "                            \"isAutoSave\": true,\n",
        "                            \"modelTechnique\": \"ExtraTreesClassifierGini\",\n",
        "                            \"modelDescription\": \"1\"\n",
        "                        },\n",
        "                        {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"NaiveBayesClassifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                        },\n",
        "                        {\n",
        "                        \"modelName\": \"1\",\n",
        "                        \"isAutoSave\": true,\n",
        "                        \"modelTechnique\": \"DecisionTreeClassifier\",\n",
        "                        \"modelDescription\": \"1\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"strength_metrics\": [\n",
        "                        {\n",
        "                            \"label\": \"Confusion Matrix\",\n",
        "                            \"value\": \"Confusion Matrix\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"Specifity & Sensitivity\",\n",
        "                            \"value\": \"Specifity & Sensitivity\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"Auc\",\n",
        "                            \"value\": \"Auc\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"Ks\",\n",
        "                            \"value\": \"Ks\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"Gain/Lift curve\",\n",
        "                            \"value\": \"gain/lift curve\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"Vif Test\",\n",
        "                            \"value\": \"Vif Test\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"train_test_split\": 0,\n",
        "                    \"modelTechniquesSC\": [\n",
        "                        {\n",
        "                            \"label\": \"CatboostClassifier\",\n",
        "                            \"value\": \"CatboostClassifier\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"XGBoost_Classifier\",\n",
        "                            \"value\": \"XGBoost_Classifier\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"RandomForestClassifierGini\",\n",
        "                            \"value\": \"RandomForestClassifierGini\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"LogisticRegressionClassifier\",\n",
        "                            \"value\": \"LogisticRegressionClassifier\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"ExtraTreesClassifierGini\",\n",
        "                            \"value\": \"ExtraTreesClassifierGini\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"NaiveBayesClassifier\",\n",
        "                            \"value\": \"NaiveBayesClassifier\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"label\": \"DecisionTreeClassifier\",\n",
        "                            \"value\": \"DecisionTreeClassifier\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"stability_metrics\": [\n",
        "                        {\n",
        "                            \"label\": \"CSI\",\n",
        "                            \"value\": \"CSI\"\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "                \"Best Parameters\": {\n",
        "                \"criterion\": \"gini\",\n",
        "                \"splitter\": \"best\",\n",
        "                \"max_depth\": 8,\n",
        "                \"random_state\": 5,\n",
        "                \"max_leaf_nodes\": 8,\n",
        "                \"min_samples_split\": 5\n",
        "                },\n",
        "                \"strength_metrics\": [\n",
        "                    \"confusion matrix\",\n",
        "                    \"specifity & sensitivity\",\n",
        "                    \"auc\",\n",
        "                    \"ks\",\n",
        "                    \"gain/lift curve\",\n",
        "                    \"vif test\"\n",
        "                ],\n",
        "                \"train_test_split\": 0.69,\n",
        "                \"modelTechniquesSC\": [\n",
        "                    {\n",
        "                        \"label\": \"CatboostClassifier\",\n",
        "                        \"value\": \"CatboostClassifier\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"XGBoost_Classifier\",\n",
        "                        \"value\": \"XGBoost_Classifier\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"RandomForestClassifierGini\",\n",
        "                        \"value\": \"RandomForestClassifierGini\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"LogisticRegressionClassifier\",\n",
        "                        \"value\": \"LogisticRegressionClassifier\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"ExtraTreesClassifierGini\",\n",
        "                        \"value\": \"ExtraTreesClassifierGini\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"label\": \"NaiveBayesClassifier\",\n",
        "                        \"value\": \"NaiveBayesClassifier\"\n",
        "                     },\n",
        "                     {\n",
        "                        \"label\": \"DecisionTreeClassifier\",\n",
        "                        \"value\": \"DecisionTreeClassifier\"\n",
        "                     }\n",
        "                ],\n",
        "                \"stability_metrics\": [\n",
        "                    \"csi\"\n",
        "                ]\n",
        "            },\n",
        "            \"description\": \"1\",\n",
        "            \"parameters\": {\n",
        "              \"criterion\": [\n",
        "                    \"gini\"\n",
        "                ],\n",
        "                \"splitter\": [\n",
        "                    \"best\"\n",
        "                ],\n",
        "                \"max_depth\": [\n",
        "                    4,\n",
        "                    9\n",
        "                ],\n",
        "                \"random_state\": [\n",
        "                    10,\n",
        "                    20\n",
        "                ],\n",
        "                \"max_leaf_nodes\": [\n",
        "                    4,\n",
        "                    10\n",
        "                ],\n",
        "                \"Best Parameters\": {\n",
        "                \"criterion\": \"gini\",\n",
        "                \"splitter\": \"best\",\n",
        "                \"max_depth\": 8,\n",
        "                \"random_state\": 5,\n",
        "                \"max_leaf_nodes\": 8,\n",
        "                \"min_samples_split\": 5\n",
        "                },\n",
        "                \"min_samples_split\": [\n",
        "                    4,\n",
        "                    10\n",
        "                ]\n",
        "            },\n",
        "            \"summary_stats\": {\n",
        "                \"DecisionTreeClassifier\": {\n",
        "                    \"f1\": 0.3667,\n",
        "                    \"recall\": 0.234,\n",
        "                    \"accuracy\": 0.6807,\n",
        "                    \"precision\": 0.8462\n",
        "                }\n",
        "            },\n",
        "            \"saved_for_doc\": true,\n",
        "            \"external_pkl\": false,\n",
        "            \"pkl_file\": \"https://nimbusuno.s3.amazonaws.com/NimbusFileManagement/NimbusUsers/Uat/qa_team/Pkls/ModelEstimation/2181.pkl?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA4IQTSJNFWGXCY552%2F20230516%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20230516T061139Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=a4d3626ef884423b4723ab8a2e7393d60803c7c553f75526f33bdbefe00dfc74\",\n",
        "            \"column_pkl_file\": null,\n",
        "            \"created\": \"2023-02-10T13:25:09.769148+05:30\",\n",
        "            \"updated\": \"2023-02-10T13:25:09.803690+05:30\",\n",
        "            \"isbigdata\": false,\n",
        "            \"model_location\": null,\n",
        "            \"library\": \"sklearn\",\n",
        "            \"target_column\": \"capsule\",\n",
        "            \"is_time_model\": false,\n",
        "            \"sas_password\": null,\n",
        "            \"sas_info\": null,\n",
        "            \"user\": 3,\n",
        "            \"username\": null,\n",
        "            \"project\": 432,\n",
        "            \"train_table_display_name\": \"table467_train_51c051\"\n",
        "        },\n",
        "        \"targetColumn\": \"capsule\",\n",
        "        \"modelTechnique\": \"DecisionTreeClassifier\",\n",
        "        \"external_pkl_value\": false\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "UenndvvYyoZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def LogisticRegressionClassifier(train, test, target, penalty=['l2'], C_low=0, C_up=4):\n",
        "    \"\"\"\n",
        "    Logistic Regression Classifier function that trains a model using a randomized search cross-validation to optimize the hyperparameters of a logistic regression classifier.\n",
        "    Parameters:\n",
        "        train (pandas.DataFrame): Training data set used to fit the model.\n",
        "        test (pandas.DataFrame): Test data set used to evaluate the model.\n",
        "        target (str): Name of the target variable in the data set.\n",
        "        penalty (list, optional): List of penalty values for the logistic regression classifier. Default is ['l2'].\n",
        "        C_low (float, optional): Lower bound for the C value. Default is 0.\n",
        "        C_up (float, optional): Upper bound for the C value. Default is 4.\n",
        "    Returns:\n",
        "        lr_class.best_estimator_ (sklearn.linear_model.LogisticRegression): Fitted logistic regression model with the best set of hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside of LogisticRegressionClassifier\")\n",
        "    scale_calculated = C_up-C_low\n",
        "    eval_metric = 'neg_log_loss'\n",
        "    para = {\n",
        "        'penalty': penalty,\n",
        "        'C': uniform(loc=C_low, scale=scale_calculated)\n",
        "    }\n",
        "    classifier = LogisticRegression(n_jobs=6)\n",
        "    lr_class = model_selection.RandomizedSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_distributions=para,\n",
        "        scoring=eval_metric,\n",
        "        verbose=10,\n",
        "        n_iter=2,\n",
        "    )\n",
        "    lr_class.fit(train.drop(labels=target, axis=1).values,\n",
        "                 train[target].values)\n",
        "    logger.info(\"End of LogisticRegressionClassifier\")\n",
        "    return lr_class.best_estimator_\n",
        "\n"
      ],
      "metadata": {
        "id": "nTvkEaAkX9zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Naive Bayes Classification\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as Sns\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "rep_0 = SimpleImputer(missing_values=0, strategy=\"mean\")\n",
        "\n",
        "cols = X_train.columns\n",
        "X_train = pd.<a onclick=\"parent.postMessage({'referent':'.pandas.DataFrame'}, '*')\">DataFrame(rep_0.fit_transform(X_train))\n",
        "X_test = pd.<a onclick=\"parent.postMessage({'referent':'.pandas.DataFrame'}, '*')\">DataFrame(rep_0.fit_transform(X_test))\n",
        "X_train.columns = cols\n",
        "X_test.columns = cols\n",
        "X_train.head()\n",
        "\n",
        "#Predicting train and test accuracy\n",
        "\n",
        "predict_train = model.fit(X_train, y_train).predict(X_train)\n",
        "\n",
        "# Accuray Score on train dataset a\n",
        "\n",
        "accuracy_train = accuracy_score(y_train,predict_train)\n",
        "print('accuracy_score on train dataset : ', accuracy_train)\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(X_test)\n",
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(y_test,predict_test)\n",
        "print('accuracy_score on test dataset : ', accuracy_test)"
      ],
      "metadata": {
        "id": "19T3Iyqf0UfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = pd.read_csv('/content/data.csv')\n",
        "X = data.iloc[:,1:]\n",
        "y = data.iloc[:,0]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size = 0.3) \n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB as KNN               # GaussianNB, BernoulliNB, MultinomialNB,\n",
        "from sklearn.model_selection import RandomizedSearchCV              # CategoricalNB, ComplementNB, out of core NB  \n",
        "\n",
        "\n",
        "                                                                                                 \n",
        "                                                \n",
        "\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'var_smoothing': np.logspace(0, -9, num=10)\n",
        "}\n",
        "\n",
        "knn_ = KNN()\n",
        "knn = RandomizedSearchCV(estimator = knn_, param_distributions = param_grid, n_iter = 100, cv = 2, verbose=2, random_state=42, n_jobs = -1)\n",
        "knn.fit(X_train, y_train) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "wzG304URQYKk",
        "outputId": "573e47bb-14ff-4666-ac8c-b4cade8ec9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e43ba7474627>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(knn, 'Hyperparameter_model_G.pkl') "
      ],
      "metadata": {
        "id": "0Gj8jKu8QYHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_from_joblib = joblib.load(open('Hyperparameter_model_G.pkl','rb'))"
      ],
      "metadata": {
        "id": "kUT8ju-TTiJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BYrQ36jx5fBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9DAY2755e-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recalibrate_execution(body):\n",
        "    \"\"\"\n",
        "    This function takes figure as an input and return the customized figure with changes in font and color\n",
        "\n",
        "    Args:\n",
        "        body (str): dtype\n",
        "    \"\"\"\n",
        "    try:\n",
        "        task_id = body['task_id']\n",
        "        DType = body[\"Dtype\"]\n",
        "        user_ = body['username']\n",
        "        data = read_para(task_id, DType, user_)\n",
        "        id = data[\"id\"]\n",
        "        table_dict = read_para_table(task_id, DType, user_)\n",
        "        userr = User.objects.get(username=data[\"user\"])\n",
        "        Tr = PerformanceTaskReview.objects.get(id=id)\n",
        "        project_id = data['project_id']\n",
        "\n",
        "        params = data['formParameters']['model']['hypertune_data']['parameters']\n",
        "        for model_name, inner_dict in params.items():\n",
        "            # Create a new inner dictionary with the updated keys\n",
        "            new_inner_dict = {}\n",
        "            for old_key, value in inner_dict.items():\n",
        "                new_key = key_mapping.get(old_key, old_key)\n",
        "                new_inner_dict[new_key] = value\n",
        "            params[model_name].clear()\n",
        "            params[model_name].update(new_inner_dict)\n",
        "\n",
        "        output_artifact = {\"outputs\": []}\n",
        "        if (data[\"is_bigdata\"] == False):\n",
        "            call_model_dict = read_para_modal(task_id, DType, user_)\n",
        "            call_model_json = call_model_dict[\"call_model\"]\n",
        "            call_model = jsonpickle.decode(call_model_json)\n",
        "\n",
        "            Manager = Model_helper(username=data[\"user\"])\n",
        "            if data[\"action\"] == \"save\":\n",
        "                Manager.Save_to_s3(\n",
        "                    data[\"modelname\"],\n",
        "                    call_model,\n",
        "                    data[\"table_name\"],\n",
        "                    data[\"target_column\"],\n",
        "                    data[\"hyperparameter\"],\n",
        "                )\n",
        "                msg = c_mt.model\n",
        "\n",
        "        try:\n",
        "            metrics = table_dict[\"table\"]\n",
        "            graph = body[\"charts\"]\n",
        "            titles = graph['title']\n",
        "            charts = []\n",
        "            for title, cc__id, c_key in zip(titles, graph['id'], graph['key']):\n",
        "                chart = update_chart_obj(\n",
        "                    cc_id=cc__id, ckey=c_key, column_name=data[\"target_column\"], bucket_name=BUCKET_NAME, task=Tr, title1=title)\n",
        "                output_artifact['outputs'].append(\n",
        "                    {\"type\": \"chart\", \"key\": cc__id, \"label\": title.get('title')})\n",
        "                charts.append(chart)\n",
        "\n",
        "            table_id = []\n",
        "            table_res_f = []\n",
        "\n",
        "            tid = save_table(\n",
        "                user=userr,\n",
        "                table_name=data[\"table_name\"],\n",
        "                data=metrics,\n",
        "                column_names=data[\"target_column\"],\n",
        "                operation=MTConstant['MR']['operations']['MC']['key'],\n",
        "                module=ModuleName,\n",
        "                submodule=MTConstant['MR']['key'],\n",
        "                project_id=data[\"project_id\"], task_id=Tr\n",
        "            )\n",
        "            table_id.append(tid)\n",
        "            table_res_f.append({\n",
        "                \"id\": tid,\n",
        "                \"data\": metrics,\n",
        "                \"header\": \"Calibration Table\",\n",
        "                \"code\":t_codes[\"Recalibrate\"],\n",
        "                \"status\": 200,\n",
        "                \"msg\": c_mt.table_success,\n",
        "            })\n",
        "            output_artifact['outputs'].append(\n",
        "                {\"type\": \"table\", \"key\": tid, \"label\": table_res_f[0]['header']})\n",
        "            \n",
        "            for model_name,inner_dict in params.items():\n",
        "                table_df = pd.DataFrame({'metrics':inner_dict.keys(),\n",
        "                    'values':inner_dict.values()})\n",
        "                table_data = table_df.to_dict('records')\n",
        "                tb = save_table(\n",
        "                            user=userr,\n",
        "                            table_name=data[\"table_name\"],\n",
        "                            column_names=data[\"target_column\"],\n",
        "                            data=table_data,\n",
        "                            project_id=data[\"project_id\"],\n",
        "                            module=ModuleName,\n",
        "                            submodule=MTConstant['MR']['key'],\n",
        "                            operation=MTConstant['MR']['operations']['MC']['key'],\n",
        "                            task_id=Tr,\n",
        "                            )\n",
        "                table_id.append(tb)\n",
        "                table_res_f.append({\n",
        "                    \"modelTechnique\": model_name,\n",
        "                    \"data\": table_data,\n",
        "                    \"header\": model_name,\n",
        "                    \"id\": tb,\n",
        "                    \"type\": \"train\",\n",
        "                    \"msg\": c_mt.table_success,\n",
        "                    \"status\": 200,\n",
        "                        })\n",
        "                # response[\"tables\"].append(x)\n",
        "                # response[\"table_id\"].append(tb.id)\n",
        "                output_artifact[\"outputs\"].append(\n",
        "                    {\"type\": \"table\", \"key\": tb, \"label\": model_name}\n",
        "                )\n",
        "\n",
        "            final_res = {\n",
        "                \"isChart\": True,\n",
        "                \"isTable\": True,\n",
        "                \"charts\": charts,\n",
        "                \"tables\": table_res_f,\n",
        "                \"table_id\": table_id,\n",
        "                \"status\": 200,\n",
        "                \"msg\": \"Operation implememnted successfully\",\n",
        "            }\n",
        "            user = data['user']\n",
        "            S3.put_object(Key=f\"NimbusFileManagement/NimbusUsers/{DType}/{user}/Outputs/{task_id}.json\",\n",
        "                          Body=json.dumps(final_res),\n",
        "                          Bucket=BUCKET_NAME)\n",
        "            Tr.task_status = \"SUCCESS\"\n",
        "            Tr.end_time = datetime.now()\n",
        "            Tr.percent_progress = 100\n",
        "            Tr.artifacts.update(output_artifact)\n",
        "            Tr.save()\n",
        "\n",
        "            # data lock function to unlock\n",
        "            table_data_unlock(data.get(\"table_name\"), user)\n",
        "            logger.info(f'Task_Id--{task_id}  Completed Successfully ')\n",
        "            pushnotification(operation=MTConstant['MR']['operations']['MC']['key'], module=ModuleName, submodule=MTConstant['MR']['key'], user=data[\"user\"],\n",
        "                             task_id=task_id, project_id=project_id, status=\"Success\", task_name=Tr.task_name)\n",
        "\n",
        "        except Exception as ex:\n",
        "            Tr.task_status = \"FAILED\"\n",
        "            Tr.failure_msg = str(ex)\n",
        "            Tr.end_time = datetime.now()\n",
        "            Tr.save()\n",
        "            user = data['user']\n",
        "            table_data_unlock(data.get(\"table_name\"), user)\n",
        "            tb = traceback.format_exc()\n",
        "            logger.error(msg=f\"Exception in : {tb}, {ex}\", project_id=data.get(\n",
        "                'project_id'), user_id=data.get('user'))\n",
        "            pushnotification(operation=MTConstant['MR']['operations']['MC']['key'], module=ModuleName, submodule=MTConstant['MR']['key'], user=data[\"user\"],\n",
        "                             task_id=task_id, project_id=project_id, status=\"Failed\", task_name=Tr.task_name)\n",
        "\n",
        "    except Exception as e:\n",
        "        tb = traceback.format_exc()\n",
        "        logger.error(msg=f\"Exception in : {tb}, {e}\")\n",
        "        pushnotification(operation=MTConstant['MR']['operations']['MC']['key'], module=ModuleName, submodule=MTConstant['MR']['key'], user=data[\"user\"],\n",
        "                         task_id=task_id, project_id=project_id, status=\"Failed\", task_name=Tr.task_name)\n"
      ],
      "metadata": {
        "id": "yk12-Ne65e7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    \n",
        "key_mapping = {\n",
        "    'n_low': 'minimum samples',\n",
        "    'cb_low': 'minimum child weight',\n",
        "    'mdl_low': 'minimum split',\n",
        "    'n_upper': 'maximum samples',\n",
        "    'cb_upper': 'maximum child weight',\n",
        "    'lr_lower': 'lower learning rate',\n",
        "    'lr_upper': 'upper learning rate',\n",
        "    'depth_low': 'minimum depth',\n",
        "    'mdl_upper': 'maximum split',\n",
        "    'depth_upper': 'maximum depth',\n",
        "    'lr_up': 'upper learning rate',\n",
        "    'md_up': 'maximum depth',\n",
        "    'lr_low': 'lower learning rate',\n",
        "    'md_low': 'minimum depth',\n",
        "    'maxIter': 'maximum iterations',\n",
        "    'maxbins': 'maximum bins',\n",
        "    'minIter': 'minimum iterations',\n",
        "    'minbins': 'minimum bins',\n",
        "    'nest_up': 'maximum estimators',\n",
        "    'maxDepth': 'maximum depth',\n",
        "    'minDepth': 'minimum depth',\n",
        "    'maxTrees': 'maximum trees',\n",
        "    'minTrees': 'minimum trees',\n",
        "    'nest_low': 'minimum estimators',\n",
        "    'colsample_bytree_up': 'maximum colsample bytree',\n",
        "    'colsample_bytree_low': 'minimum colsample bytree',\n",
        "    'nfold': 'number of folds',\n",
        "    'nj_up': 'maximum number of trees in the forest',\n",
        "    'msl_up': 'maximum samples required to split an internal node',\n",
        "    'mss_up': 'maximum samples required to be at a leaf node',\n",
        "    'nj_low': 'minimum number of trees in the forest',\n",
        "    'msl_low': 'minimum samples required to split an internal node',\n",
        "    'mss_low': 'minimum samples required to be at a leaf node',\n",
        "    'c_up': 'maximum regularization strength', \n",
        "    'c_low': 'minimum regularization strength',\n",
        "    'maxregParam': 'maximum regularization parameter', \n",
        "    'minregParam': 'minimum regularization parameter'\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "-R9GZSJz5e3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def recalibrate_execution(body):\n",
        "    \"\"\"\n",
        "    This function takes figure as an input and return the customized figure with changes in font and color\n",
        "\n",
        "    Args:\n",
        "        body (str): dtype\n",
        "    \"\"\"\n",
        "    try:\n",
        "        task_id = body['task_id']\n",
        "        DType = body[\"Dtype\"]\n",
        "        user_ = body['username']\n",
        "        data = read_para(task_id, DType, user_)\n",
        "        id = data[\"id\"]\n",
        "        table_dict = read_para_table(task_id, DType, user_)\n",
        "        userr = User.objects.get(username=data[\"user\"])\n",
        "        Tr = PerformanceTaskReview.objects.get(id=id)\n",
        "        project_id = data['project_id']\n",
        "\n",
        "        # params = data['formParameters']['model']['hypertune_data']['parameters']\n",
        "        # print(data)\n",
        "        # print(params)\n",
        "        # for model_name, inner_dict in params.items():\n",
        "        #     # Create a new inner dictionary with the updated keys\n",
        "        #     new_inner_dict = {}\n",
        "        #     for old_key, value in inner_dict.items():\n",
        "        #         new_key = key_mapping.get(old_key, old_key)\n",
        "        #         new_inner_dict[new_key] = value\n",
        "        #     params[model_name].clear()\n",
        "        #     params[model_name].update(new_inner_dict)\n",
        "        # print(inner_dict)\n",
        "        # print(params.items())\n",
        "\n",
        "        params = data['formParameters']['model']['hypertune_data']['parameters']\n",
        "        print(data['modelname'])\n",
        "        print(data['hyperparameter'])\n",
        "        print(data)\n",
        "        print(params)\n",
        "        for model_name, inner_dict in params.items():\n",
        "            # Create a new inner dictionary with the updated keys\n",
        "            if model_name == data['modelname']:\n",
        "                new_inner_dict = {}\n",
        "                for old_key, value in inner_dict.items():\n",
        "                    new_key = key_mapping.get(old_key, old_key)\n",
        "                    new_inner_dict[new_key] = value\n",
        "                params[model_name].clear()\n",
        "                params[model_name].update(new_inner_dict)\n",
        "                break\n",
        "\n",
        "        print(inner_dict)\n",
        "        print(params.items())\n",
        "\n",
        "\n",
        "        output_artifact = {\"outputs\": []}\n",
        "        if (data[\"is_bigdata\"] == False):\n",
        "            call_model_dict = read_para_modal(task_id, DType, user_)\n",
        "            call_model_json = call_model_dict[\"call_model\"]\n",
        "            call_model = jsonpickle.decode(call_model_json)\n",
        "\n",
        "            Manager = Model_helper(username=data[\"user\"])\n",
        "            if data[\"action\"] == \"save\":\n",
        "                Manager.Save_to_s3(\n",
        "                    data[\"modelname\"],\n",
        "                    call_model,\n",
        "                    data[\"table_name\"],\n",
        "                    data[\"target_column\"],\n",
        "                    data[\"hyperparameter\"],\n",
        "                )\n",
        "                msg = c_mt.model\n",
        "\n",
        "        try:\n",
        "            metrics = table_dict[\"table\"]\n",
        "            graph = body[\"charts\"]\n",
        "            titles = graph['title']\n",
        "            charts = []\n",
        "            for title, cc__id, c_key in zip(titles, graph['id'], graph['key']):\n",
        "                chart = update_chart_obj(\n",
        "                    cc_id=cc__id, ckey=c_key, column_name=data[\"target_column\"], bucket_name=BUCKET_NAME, task=Tr, title1=title)\n",
        "                output_artifact['outputs'].append(\n",
        "                    {\"type\": \"chart\", \"key\": cc__id, \"label\": title.get('title')})\n",
        "                charts.append(chart)\n",
        "\n",
        "            table_id = []\n",
        "            table_res_f = []\n",
        "\n",
        "            tid = save_table(\n",
        "                user=userr,\n",
        "                table_name=data[\"table_name\"],\n",
        "                data=metrics,\n",
        "                column_names=data[\"target_column\"],\n",
        "                operation=MTConstant['MR']['operations']['MC']['key'],\n",
        "                module=ModuleName,\n",
        "                submodule=MTConstant['MR']['key'],\n",
        "                project_id=data[\"project_id\"], task_id=Tr\n",
        "            )\n",
        "            table_id.append(tid)\n",
        "            table_res_f.append({\n",
        "                \"id\": tid,\n",
        "                \"data\": metrics,\n",
        "                \"header\": \"Calibration Table\",\n",
        "                \"code\":t_codes[\"Recalibrate\"],\n",
        "                \"status\": 200,\n",
        "                \"msg\": c_mt.table_success,\n",
        "            })\n",
        "            output_artifact['outputs'].append(\n",
        "                {\"type\": \"table\", \"key\": tid, \"label\": table_res_f[0]['header']})\n",
        "            \n",
        "            for model_name,inner_dict in params.items():\n",
        "                print(model_name)\n",
        "                print(inner_dict)\n",
        "                print(inner_dict.keys())\n",
        "                if model_name == data['modelname']:\n",
        "                    # table_df = pd.DataFrame()\n",
        "                    lis_ = []\n",
        "                    val_lo = []\n",
        "                    val_up = []\n",
        "                    for i in inner_dict.keys():\n",
        "                        if i.split()[0] == 'minimum' or i.split()[0] == 'lower':\n",
        "                            text = i.split()[1:]\n",
        "                            lis_.append(' '.join(text).capitalize())                              # ' '.join(text)\n",
        "                            val_lo.append(inner_dict[i])\n",
        "                        elif i.split()[0] == 'maximum' or i.split()[0] == 'upper':\n",
        "                            val_up.append(inner_dict[i])\n",
        "\n",
        "                    table = {'Parameters': lis_,\n",
        "                            'Lower Values': val_lo,\n",
        "                            'Upper Values' : val_up,\n",
        "                          }\n",
        "                    table_df = pd.DataFrame(table)\n",
        "\n",
        "                    print(table_df)\n",
        "                    table_data = table_df.to_dict('records')\n",
        "                    print(table_data)\n",
        "                    tb = save_table(\n",
        "                                user=userr,\n",
        "                                table_name=data[\"table_name\"],\n",
        "                                column_names=data[\"target_column\"],\n",
        "                                data=table_data,\n",
        "                                project_id=data[\"project_id\"],\n",
        "                                module=ModuleName,\n",
        "                                submodule=MTConstant['MR']['key'],\n",
        "                                operation=MTConstant['MR']['operations']['MC']['key'],\n",
        "                                task_id=Tr,\n",
        "                                )\n",
        "                    table_id.append(tb)\n",
        "                    table_res_f.append({\n",
        "                        \"modelTechnique\": model_name,\n",
        "                        \"data\": table_data,\n",
        "                        \"header\": model_name + \" Parameter Table \",\n",
        "                        \"id\": tb,\n",
        "                        \"type\": \"train\",\n",
        "                        \"msg\": c_mt.table_success,\n",
        "                        \"status\": 200,\n",
        "                            })\n",
        "                    output_artifact[\"outputs\"].append(\n",
        "                        {\"type\": \"table\", \"key\": tb, \"label\": model_name + \" Parameter Table \"}\n",
        "                    )\n",
        "                    break\n",
        "\n",
        "            final_res = {\n",
        "                \"isChart\": True,\n",
        "                \"isTable\": True,\n",
        "                \"charts\": charts,\n",
        "                \"tables\": table_res_f,\n",
        "                \"table_id\": table_id,\n",
        "                \"status\": 200,\n",
        "                \"msg\": \"Operation implememnted successfully\",\n",
        "            }\n",
        "            user = data['user']\n",
        "            S3.put_object(Key=f\"NimbusFileManagement/NimbusUsers/{DType}/{user}/Outputs/{task_id}.json\",\n",
        "                          Body=json.dumps(final_res),\n",
        "                          Bucket=BUCKET_NAME)\n",
        "            Tr.task_status = \"SUCCESS\"\n",
        "            Tr.end_time = datetime.now()\n",
        "            Tr.percent_progress = 100\n",
        "            Tr.artifacts.update(output_artifact)\n",
        "            Tr.save()\n",
        "\n",
        "            # data lock function to unlock\n",
        "            table_data_unlock(data.get(\"table_name\"), user)\n",
        "            logger.info(f'Task_Id--{task_id}  Completed Successfully ')\n",
        "            pushnotification(operation=MTConstant['MR']['operations']['MC']['key'], module=ModuleName, submodule=MTConstant['MR']['key'], user=data[\"user\"],\n",
        "                             task_id=task_id, project_id=project_id, status=\"Success\", task_name=Tr.task_name)\n",
        "\n",
        "        except Exception as ex:\n",
        "            Tr.task_status = \"FAILED\"\n",
        "            Tr.failure_msg = str(ex)\n",
        "            Tr.end_time = datetime.now()\n",
        "            Tr.save()\n",
        "            user = data['user']\n",
        "            table_data_unlock(data.get(\"table_name\"), user)\n",
        "            tb = traceback.format_exc()\n",
        "            print(tb)\n",
        "            logger.error(msg=f\"Exception in : {tb}, {ex}\", project_id=data.get(\n",
        "                'project_id'), user_id=data.get('user'))\n",
        "            pushnotification(operation=MTConstant['MR']['operations']['MC']['key'], module=ModuleName, submodule=MTConstant['MR']['key'], user=data[\"user\"],\n",
        "                             task_id=task_id, project_id=project_id, status=\"Failed\", task_name=Tr.task_name)\n",
        "\n",
        "    except Exception as e:\n",
        "        tb = traceback.format_exc()\n",
        "        print(tb)\n",
        "        logger.error(msg=f\"Exception in : {tb}, {e}\")\n",
        "        pushnotification(operation=MTConstant['MR']['operations']['MC']['key'], module=ModuleName, submodule=MTConstant['MR']['key'], user=data[\"user\"],\n",
        "                         task_id=task_id, project_id=project_id, status=\"Failed\", task_name=Tr.task_name)\n"
      ],
      "metadata": {
        "id": "7gU0PCNS5e0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   \n",
        "key_mapping = {\n",
        "    'n_low': 'minimum samples',\n",
        "    'cb_low': 'minimum child weight',\n",
        "    'mdl_low': 'minimum min_samples_split',\n",
        "    'n_upper': 'maximum samples',\n",
        "    'cb_upper': 'maximum child weight',\n",
        "    'lr_lower': 'lower learning_rate',\n",
        "    'lr_upper': 'upper learning_rate',\n",
        "    'depth_low': 'minimum max_depth',\n",
        "    'mdl_upper': 'maximum min_samples_split',\n",
        "    'depth_upper': 'maximum max_depth',\n",
        "    'lr_up': 'upper learning_rate',\n",
        "    'md_up': 'maximum max_depth',\n",
        "    'lr_low': 'lower learning_rate',\n",
        "    'md_low': 'minimum max_depth',\n",
        "    'maxIter': 'maximum iterations',\n",
        "    'maxbins': 'maximum bins',\n",
        "    'minIter': 'minimum iterations',\n",
        "    'minbins': 'minimum bins',\n",
        "    'nest_up': 'maximum estimators',\n",
        "    'maxDepth': 'maximum max_depth',\n",
        "    'minDepth': 'minimum max_depth',\n",
        "    'maxTrees': 'maximum trees',\n",
        "    'minTrees': 'minimum trees',\n",
        "    'nest_low': 'minimum estimators',\n",
        "    'colsample_bytree_up': 'maximum colsample_bylevel',\n",
        "    'colsample_bytree_low': 'minimum colsample_bylevel',\n",
        "    'nfold': 'number of folds',\n",
        "    'nj_up': 'maximum number of trees in the forest',\n",
        "    'msl_up': 'maximum min_samples_split',\n",
        "    'mss_up': 'maximum min_samples_leaf',\n",
        "    'nj_low': 'minimum number of trees in the forest',\n",
        "    'msl_low': 'minimum min_samples_split',\n",
        "    'mss_low': 'minimum min_samples_leaf',\n",
        "    'c_up': 'maximum regularization strength', \n",
        "    'c_low': 'minimum regularization strength',\n",
        "    'maxregParam': 'maximum regularization parameter', \n",
        "    'minregParam': 'minimum regularization parameter'\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "nekcDpugIfby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = ['kishan', 'is', 'boy']\n",
        "st = 'kishan is boy'\n",
        "\n",
        "st.split(' ')[1:]\n",
        "print(st.capitalize())"
      ],
      "metadata": {
        "id": "kQZlJSag5exa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be5a7fd-a92c-4b4a-ae2e-47e362bcac3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kishan is boy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list_p = ['max_depth','n_estimators','min_samples_leaf','min_samples_split','colsample_bylevel']\n",
        "\n",
        "#         for i in data['hyperparameter'].keys():\n",
        "#             for para in list_p:\n",
        "#                 if i == para:"
      ],
      "metadata": {
        "id": "TAWTd7wV5euh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = [1,2,3,4,5,6]\n",
        "\n",
        "l.insert(0,'saa')\n",
        "print(l)"
      ],
      "metadata": {
        "id": "I7HhSRHs5era",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e82429-17ff-4e34-ce95-72ac6503dd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['saa', 1, 2, 3, 4, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "  \n",
        "# initialize list of lists\n",
        "data = [['tom', 10], ['nick', 15], ['juli', 14]]\n",
        "  \n",
        "# Create the pandas DataFrame\n",
        "df = pd.DataFrame(data, columns=['Name', 'Age'])\n",
        "  \n",
        "# print dataframe.\n",
        "df"
      ],
      "metadata": {
        "id": "OHDNl7985eoz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "8eff8fa9-9a6b-4bd8-fbb3-78370a500693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1144fc459d96>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create the pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print dataframe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    752\u001b[0m                         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                     )\n\u001b[0;32m--> 754\u001b[0;31m                     mgr = arrays_to_mgr(\n\u001b[0m\u001b[1;32m    755\u001b[0m                         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                         \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7331\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7332\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7333\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_with_infer\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".*the Index constructor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_dtype_obj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_multi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scalar_data_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__array__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Index(...) must be called with a collection of some kind, False was passed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = {5}\n",
        "print(list(a))"
      ],
      "metadata": {
        "id": "IypUZGNS5elb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20048dbc-4d1d-4744-94c2-87c544aeaecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = []\n",
        "l = [1,2,3]\n",
        "# print(l.insert(0,9))\n",
        "m.append(l.insert(0,9))\n",
        "print(l)\n",
        "print(m)"
      ],
      "metadata": {
        "id": "wkNRy6bH5eij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ae313d-24ec-4c86-b921-5b01f4c9cf82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9, 1, 2, 3]\n",
            "[None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = [1,2,3]\n",
        "l.insert(0,9)\n",
        "print(l)"
      ],
      "metadata": {
        "id": "SfOi6HtU5efA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6c1147-3ce2-4306-9852-4066b3ebccaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9, 1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from Performance.Scripts.Helper_Script import fetch_data_as_df, save_chart_to_s3, update_chart3, update_chart_html, Helper,progress_bar_update, send_msg_to_sqs,store\n",
        "from Performance.Scripts.read_para import read_para\n",
        "from scikitplot.helpers import binary_ks_curve\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from scikitplot.helpers import cumulative_gain_curve\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, log_loss, roc_curve, auc, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from scipy.stats import uniform\n",
        "from sklearn import metrics\n",
        "from sklearn import ensemble\n",
        "from matplotlib.style import library\n",
        "from Performance.Scripts.global_var import BUCKET_NAME, InternalQueue, logger, aws_region\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, neighbors\n",
        "from io import StringIO\n",
        "import plotly.graph_objects as go\n",
        "import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import jsonpickle\n",
        "import traceback\n",
        "import catboost\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import math\n",
        "import json\n",
        "import boto3\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "def data_types(data):\n",
        "    \"\"\"\n",
        "    This function takes a Pandas dataframe as input and returns a modified version of the dataframe.\n",
        "    Args:\n",
        "        data: Pandas dataframe containing the data\n",
        "    Returns:\n",
        "        X: modified version of the input dataframe where all object type columns \n",
        "            have been converted to numerical type using Label Encoding.\n",
        "    \"\"\"\n",
        "    X = data\n",
        "    objList = X.select_dtypes(include=\"object\").columns\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    for feat in objList:\n",
        "        X[feat] = le.fit_transform(X[feat].astype(str))\n",
        "    return X\n",
        "\n",
        "\n",
        "def checker(df):\n",
        "    \"\"\"\n",
        "     Check if the input dataframe contains missing values. \n",
        "     returns 1 if the dataframe does not contain missing values and 0 if it does.\n",
        "    \"\"\"\n",
        "    if (df.isnull().sum().sum()) > 0:\n",
        "        raise (\n",
        "            'Error. Data Contains Missing Values. Please Do Missing value treatment to do this step.')\n",
        "        return 0\n",
        "    return 1\n",
        "\n",
        "\n",
        "def target_valid(data):\n",
        "    \"\"\"\n",
        "    This function returns a list of column names from a Pandas DataFrame that contain only 2 or fewer unique values.\n",
        "    Args:\n",
        "        data (pandas.DataFrame): A Pandas DataFrame containing the data.\n",
        "    Returns:\n",
        "        valid_col (list): A list of column names from the input DataFrame that contain only 2 or fewer unique values.\n",
        "    \"\"\"\n",
        "\n",
        "    valid_col = []\n",
        "    col = list(data.columns)\n",
        "    for fet in col:\n",
        "        x = len(np.unique(data[fet]))\n",
        "        if (x < 3):\n",
        "            valid_col.append(fet)\n",
        "    return valid_col\n",
        "\n",
        "\n",
        "def ExtraTreesClassifierEntr(train, test, target, nest_low=100, nest_up=1400, nj_low=1, nj_up=2, md_low=4,\n",
        "                             md_up=10, mss_low=2, mss_up=3, msl_low=1, msl_up=2):\n",
        "    \"\"\"\n",
        "    A function that trains an ExtraTreesClassifier model using a randomized search over hyperparameters and \n",
        "    returns the best estimator.\n",
        "    Args:\n",
        "        train (pd.DataFrame): A pandas dataframe containing the training data.\n",
        "        test (pd.DataFrame): A pandas dataframe containing the testing data.\n",
        "        target (str): The target column of the data.\n",
        "        nest_low (int): The lower bound of the number of estimators. Default is 100.\n",
        "        nest_up (int): The upper bound of the number of estimators. Default is 1400.\n",
        "        nj_low (int): The lower bound of the number of jobs. Default is 1.\n",
        "        nj_up (int): The upper bound of the number of jobs. Default is 2.\n",
        "        md_low (int): The lower bound of the maximum depth. Default is 4.\n",
        "        md_up (int): The upper bound of the maximum depth. Default is 10.\n",
        "        mss_low (int): The lower bound of the minimum samples split. Default is 2.\n",
        "        mss_up (int): The upper bound of the minimum samples split. Default is 3.\n",
        "        msl_low (int): The lower bound of the minimum samples leaf. Default is 1.\n",
        "        msl_up (int): The upper bound of the minimum samples leaf. Default is 2.\n",
        "    Returns:\n",
        "        The best estimator from the ExtraTreesClassifier model.\n",
        "    \"\"\"\n",
        "    logger.info(\"Inside ExtraTreesClassifierEntr \")\n",
        "    eval_metric = 'neg_log_loss'\n",
        "\n",
        "    para = {\n",
        "        'criterion': ['entropy'],\n",
        "        'n_estimators': np.arange(nest_low, nest_up+1),\n",
        "        'n_jobs': np.arange(nj_low, nj_up+1),\n",
        "        'max_depth': np.arange(md_low, md_up+1),\n",
        "        'min_samples_split': np.arange(mss_low, mss_up+1),\n",
        "        'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
        "        'min_samples_leaf': np.arange(msl_low, msl_up+1),\n",
        "\n",
        "    }\n",
        "    # using random search cause it is faster and gave nearly identical results as optuna.\n",
        "    classifier = ensemble.ExtraTreesClassifier(n_jobs=6)\n",
        "    extree = model_selection.RandomizedSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_distributions=para,\n",
        "        scoring=eval_metric,\n",
        "        verbose=10,\n",
        "        n_iter=2,\n",
        "    )\n",
        "    extree.fit(train.drop(labels=target, axis=1).values, train[target].values)\n",
        "    logger.info(\"end of ExtraTreesClassifierEntr \")\n",
        "    return extree.best_estimator_\n",
        "\n",
        "\n",
        "def ExtraTreesClassifiergini(train, test, target, nest_low=100, nest_up=1400, nj_low=1, nj_up=2, md_low=4,\n",
        "                             md_up=10, mss_low=2, mss_up=3, msl_low=1, msl_up=2):\n",
        "    \"\"\"\n",
        "    A function that trains an ExtraTreesClassifier model with 'gini' criterion using a\n",
        "    randomized search over hyperparameters and returns the best estimator.\n",
        "    Args:\n",
        "        train (pd.DataFrame): A pandas dataframe containing the training data.\n",
        "        test (pd.DataFrame): A pandas dataframe containing the testing data.\n",
        "        target (str): The target column of the data.\n",
        "        nest_low (int): The lower bound of the number of estimators. Default is 100.\n",
        "        nest_up (int): The upper bound of the number of estimators. Default is 1400.\n",
        "        nj_low (int): The lower bound of the number of jobs. Default is 1.\n",
        "        nj_up (int): The upper bound of the number of jobs. Default is 2.\n",
        "        md_low (int): The lower bound of the maximum depth. Default is 4.\n",
        "        md_up (int): The upper bound of the maximum depth. Default is 10.\n",
        "        mss_low (int): The lower bound of the minimum samples split. Default is 2.\n",
        "        mss_up (int): The upper bound of the minimum samples split. Default is 3.\n",
        "        msl_low (int): The lower bound of the minimum samples leaf. Default is 1.\n",
        "        msl_up (int): The upper bound of the minimum samples leaf. Default is 2.\n",
        "    Returns:\n",
        "        The best estimator from the ExtraTreesClassifier model with 'gini' criterion.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside of ExtraTreesClassifiergini \")\n",
        "    eval_metric = 'neg_log_loss'\n",
        "\n",
        "    para = {\n",
        "        'criterion': ['gini'],\n",
        "        'n_estimators': np.arange(nest_low, nest_up+1),\n",
        "        'n_jobs': np.arange(nj_low, nj_up+1),\n",
        "        'max_depth': np.arange(md_low, md_up+1),\n",
        "        'min_samples_split': np.arange(mss_low, mss_up+1),\n",
        "        'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
        "        'min_samples_leaf': np.arange(msl_low, msl_up+1),\n",
        "\n",
        "    }\n",
        "    # using random search cause it is faster and gave nearly identical results as optuna.\n",
        "    classifier = ensemble.ExtraTreesClassifier(n_jobs=6)\n",
        "    extree = model_selection.RandomizedSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_distributions=para,\n",
        "        scoring=eval_metric,\n",
        "        verbose=10,\n",
        "        n_iter=2,\n",
        "    )\n",
        "    extree.fit(train.drop(labels=target, axis=1).values, train[target].values)\n",
        "    logger.info(\"end of ExtraTreesClassifiergini \")\n",
        "    return extree.best_estimator_\n",
        "\n",
        "\n",
        "def catboot_hypertune(train, test, target, lr_lower=1e-4, lr_upper=1e-2,\n",
        "                      depth_low=4, depth_upper=10,\n",
        "                      mdl_low=26, mdl_upper=64,\n",
        "                      n_low=100, n_upper=300,\n",
        "                      cb_low=0.2, cb_upper=1\n",
        "                      ):\n",
        "    \"\"\"\n",
        "    Perform hyperparameter tuning for a CatBoostClassifier using a random search approach.\n",
        "    Args:\n",
        "        train (pd.DataFrame): The training data.\n",
        "        test (pd.DataFrame): The test data.\n",
        "        target (str): The name of the target column in the dataframes.\n",
        "        lr_lower (float, optional): The lower bound of the learning rate range. Defaults to 1e-4.\n",
        "        lr_upper (float, optional): The upper bound of the learning rate range. Defaults to 1e-2.\n",
        "        depth_low (int, optional): The lower bound of the tree depth range. Defaults to 4.\n",
        "        depth_upper (int, optional): The upper bound of the tree depth range. Defaults to 10.\n",
        "        mdl_low (int, optional): The lower bound of the minimum number of samples per leaf range. Defaults to 26.\n",
        "        mdl_upper (int, optional): The upper bound of the minimum number of samples per leaf range. Defaults to 64.\n",
        "        n_low (int, optional): The lower bound of the number of boosting iterations range. Defaults to 100.\n",
        "        n_upper (int, optional): The upper bound of the number of boosting iterations range. Defaults to 300.\n",
        "        cb_low (float, optional): The lower bound of the column subsampling rate range. Defaults to 0.2.\n",
        "        cb_upper (float, optional): The upper bound of the column subsampling rate range. Defaults to 1.\n",
        "    Returns:\n",
        "        catboost.CatBoostClassifier: The best estimator found by the hyperparameter tuning process.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside of catboot_hypertune\")\n",
        "    cat_options = {\n",
        "        # Range[0.001, 0.5]\n",
        "        'learning_rate': np.arange(lr_lower, lr_upper, 0.005),\n",
        "        # Range[4,10]\n",
        "        'depth': np.arange(depth_low, depth_upper),\n",
        "        # Range[26,64]\n",
        "        'min_data_in_leaf': np.arange(mdl_low, mdl_upper),\n",
        "        # Range[100,500]\n",
        "        'iterations':  np.arange(n_low, n_upper),\n",
        "        # Range (0,1]\n",
        "        'colsample_bylevel': np.arange(cb_low, cb_upper, 0.2),\n",
        "    }\n",
        "    classifier = catboost.CatBoostClassifier(thread_count=6)\n",
        "    cat = model_selection.RandomizedSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_distributions=cat_options, cv=5,\n",
        "        verbose=10,\n",
        "        n_iter=2,\n",
        "    )\n",
        "    cat.fit(train.drop(labels=target, axis=1).values, train[target].values)\n",
        "    logger.info(\"end of catboot_hypertune\")\n",
        "    return cat.best_estimator_\n",
        "\n",
        "\n",
        "def RandomForestClassifierEntr(train, test, target, nest_low=100, nest_up=1400, nj_low=1, nj_up=2, md_low=4,\n",
        "                               md_up=10, mss_low=2, mss_up=3, msl_low=1, msl_up=2):\n",
        "    \"\"\"\n",
        "    Random Forest Classifier function that trains a model using a randomized search cross-validation to optimize the hyperparameters of a random forest classifier with entropy criterion.\n",
        "    Parameters:\n",
        "        train (pandas.DataFrame): Training data set used to fit the model.\n",
        "        test (pandas.DataFrame): Test data set used to evaluate the model.\n",
        "        target (str): Name of the target variable in the data set.\n",
        "        nest_low (int, optional): Lower bound for the number of trees in the forest. Default is 100.\n",
        "        nest_up (int, optional): Upper bound for the number of trees in the forest. Default is 1400.\n",
        "        nj_low (int, optional): Lower bound for the number of jobs to run in parallel. Default is 1.\n",
        "        nj_up (int, optional): Upper bound for the number of jobs to run in parallel. Default is 2.\n",
        "        md_low (int, optional): Lower bound for the maximum depth of the tree. Default is 4.\n",
        "        md_up (int, optional): Upper bound for the maximum depth of the tree. Default is 10.\n",
        "        mss_low (int, optional): Lower bound for the minimum number of samples required to split an internal node. Default is 2.\n",
        "        mss_up (int, optional): Upper bound for the minimum number of samples required to split an internal node. Default is 3.\n",
        "        msl_low (int, optional): Lower bound for the minimum number of samples required to be at a leaf node. Default is 1.\n",
        "        msl_up (int, optional): Upper bound for the minimum number of samples required to be at a leaf node. Default is 2.\n",
        "    Returns:\n",
        "        rfEntr.best_estimator_ (sklearn.ensemble.RandomForestClassifier): Fitted random forest model with the best set of hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside of RandomForestClassifierEntr\")\n",
        "    eval_metric = 'neg_log_loss'\n",
        "\n",
        "    para = {\n",
        "        'criterion': ['entropy'],\n",
        "        'n_estimators': np.arange(nest_low, nest_up+1),\n",
        "        'max_depth': np.arange(md_low, md_up+1),\n",
        "        'min_samples_split': np.arange(mss_low, mss_up+1),\n",
        "        'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
        "        'min_samples_leaf': np.arange(msl_low, msl_up+1),\n",
        "    }\n",
        "\n",
        "    classifier = ensemble.RandomForestClassifier(n_jobs=6)\n",
        "    rfEntr = model_selection.RandomizedSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_distributions=para,\n",
        "        scoring=eval_metric,\n",
        "        verbose=10, cv=3,\n",
        "        n_iter=2,\n",
        "    )\n",
        "    rfEntr.fit(train.drop(labels=target, axis=1).values, train[target].values)\n",
        "    logger.info(\"end of RandomForestClassifierEntr\")\n",
        "    return rfEntr.best_estimator_\n",
        "\n",
        "\n",
        "def RandomForestClassifiergini(train, test, target, nest_low=100, nest_up=1400, nj_low=1, nj_up=2, md_low=4,\n",
        "                               md_up=10, mss_low=2, mss_up=3, msl_low=1, msl_up=2):\n",
        "    \"\"\"\n",
        "    Train a random forest classifier model with the 'gini' criterion using the given train and test data.\n",
        "    Parameters:\n",
        "        train (pandas.DataFrame): A dataframe containing the training data.\n",
        "        test (pandas.DataFrame): A dataframe containing the testing data.\n",
        "        target (str): The name of the target column.\n",
        "        nest_low (int): The minimum number of trees in the forest. Default is 100.\n",
        "        nest_up (int): The maximum number of trees in the forest. Default is 1400.\n",
        "        nj_low (int): The minimum number of parallel jobs to run for tree building. Default is 1.\n",
        "        nj_up (int): The maximum number of parallel jobs to run for tree building. Default is 2.\n",
        "        md_low (int): The minimum depth of the trees. Default is 4.\n",
        "        md_up (int): The maximum depth of the trees. Default is 10.\n",
        "        mss_low (int): The minimum number of samples required to split an internal node. Default is 2.\n",
        "        mss_up (int): The maximum number of samples required to split an internal node. Default is 3.\n",
        "        msl_low (int): The minimum number of samples required to be at a leaf node. Default is 1.\n",
        "        msl_up (int): The maximum number of samples required to be at a leaf node. Default is 2.\n",
        "    Returns:\n",
        "        A trained random forest classifier model with the best parameters obtained through Randomized Search CV.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside of RandomForestClassifiergini\")\n",
        "    eval_metric = 'neg_log_loss'\n",
        "\n",
        "    para = { \n",
        "        'criterion': ['gini'],\n",
        "        'n_estimators': np.arange(nest_low, nest_up+1),\n",
        "        'max_depth': np.arange(md_low, md_up+1),\n",
        "        'min_samples_split': np.arange(mss_low, mss_up+1),\n",
        "        'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
        "        'min_samples_leaf': np.arange(msl_low, msl_up+1),\n",
        "    }\n",
        "\n",
        "    classifier = ensemble.RandomForestClassifier(n_jobs=6)\n",
        "    rfEntr = model_selection.RandomizedSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_distributions=para,\n",
        "        scoring=eval_metric,\n",
        "        verbose=10, cv=3,\n",
        "        n_iter=2,\n",
        "    )\n",
        "    rfEntr.fit(train.drop(labels=target, axis=1).values, train[target].values)\n",
        "    logger.info(\"end of RandomForestClassifiergini\")\n",
        "    return rfEntr.best_estimator_\n",
        "\n",
        "\n",
        "def KNeighborsClassifierDist(train, test, target, nj_low=1, nj_up=2, n_neighbors_low=1, n_neighbors_up=4):\n",
        "    \"\"\"\n",
        "    Train a K-nearest neighbors classifier model with distance-based weighting using the given train and test data.\n",
        "    Args:\n",
        "        train (pandas.DataFrame): A dataframe containing the training data.\n",
        "        test (pandas.DataFrame): A dataframe containing the testing data.\n",
        "        target (str): The name of the target column.\n",
        "        nj_low (int): The minimum number of parallel jobs to run for tree building. Default is 1.\n",
        "        nj_up (int): The maximum number of parallel jobs to run for tree building. Default is 2.\n",
        "        n_neighbors_low (int): The minimum number of neighbors to consider for classification. Default is 1.\n",
        "        n_neighbors_up (int): The maximum number of neighbors to consider for classification. Default is 4.\n",
        "    Returns:\n",
        "        A trained K-nearest neighbors classifier model with the best parameters obtained through Randomized Search CV.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside of KNeighborsClassifierDist\")\n",
        "    eval_metric = 'neg_log_loss'\n",
        "\n",
        "    para = {\n",
        "        'weights': ['distance'],\n",
        "        'n_jobs': np.arange(nj_low, nj_up),\n",
        "        'n_neighbors': np.arange(n_neighbors_low, n_neighbors_up)\n",
        "    }\n",
        "    classifier = neighbors.KNeighborsClassifier(n_jobs=6)\n",
        "    KNN_Dist = model_selection.RandomizedSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_distributions=para,\n",
        "        scoring=eval_metric,\n",
        "        verbose=10,\n",
        "        n_iter=2,\n",
        "    )\n",
        "    KNN_Dist.fit(train.drop(labels=target, axis=1).values,\n",
        "                 train[target].values)\n",
        "    logger.info(\"end of KNeighborsClassifierDist\")\n",
        "    return KNN_Dist.best_estimator_\n",
        "\n",
        "\n",
        "def KNeighborsClassifierunif(train, test, target, nj_low=1, nj_up=2, n_neighbors_low=1, n_neighbors_up=4):\n",
        "    \"\"\"\n",
        "    Trains and tunes a k-NN classifier using the uniform weighting scheme.\n",
        "    Args:\n",
        "        train(pandas.DataFrame):The training dataset.\n",
        "        test(pandas.DataFrame): The testing dataset.\n",
        "        target(str):The name of the target variable column in `train` and `test`.\n",
        "        nj_low(int, default=1):The lower bound of the number of parallel jobs to run for neighbors search.\n",
        "        nj_up(int, default=2):The upper bound of the number of parallel jobs to run for neighbors search.\n",
        "        n_neighbors_low(int, default=1):The lower bound of the number of neighbors to use for classification.\n",
        "        n_neighbors_up(int, default=4):The upper bound of the number of neighbors to use for classification.\n",
        "    Returns:\n",
        "\n",
        "        A trained k-NN classifier with the optimal hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside of KNeighborsClassifierunif\")\n",
        "    eval_metric = 'neg_log_loss'\n",
        "\n",
        "    para = {\n",
        "        'weights': ['uniform'],\n",
        "        'n_jobs': np.arange(nj_low, nj_up),\n",
        "        'n_neighbors': np.arange(n_neighbors_low, n_neighbors_up)\n",
        "    }\n",
        "    classifier = neighbors.KNeighborsClassifier(n_jobs=6)\n",
        "    KNN_Dist = model_selection.RandomizedSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_distributions=para,\n",
        "        scoring=eval_metric,\n",
        "        verbose=10,\n",
        "        n_iter=2,\n",
        "    )\n",
        "    KNN_Dist.fit(train.drop(labels=target, axis=1).values,\n",
        "                 train[target].values)\n",
        "    logger.info(\"end of KNeighborsClassifierunif\")\n",
        "    return KNN_Dist.best_estimator_\n",
        "\n",
        "\n",
        "def XGBoost_Classifier(train, test, target, lr_low=0.3, lr_up=0.4, nest_low=180, nest_up=300, md_low=3, md_up=18, colsample_bytree_low=0.5, colsample_bytree_up=1):\n",
        "    \"\"\"\n",
        "    XGBoost Classifier function that trains a model using a randomized search cross-validation to optimize the hyperparameters of an XGBoost classifier.\n",
        "    Parameters:\n",
        "        train (pandas.DataFrame): Training data set used to fit the model.\n",
        "        test (pandas.DataFrame): Test data set used to evaluate the model.\n",
        "        target (str): Name of the target variable in the data set.\n",
        "        lr_low (float, optional): Lower bound for the learning rate. Default is 0.3.\n",
        "        lr_up (float, optional): Upper bound for the learning rate. Default is 0.4.\n",
        "        nest_low (int, optional): Lower bound for the number of trees. Default is 180.\n",
        "        nest_up (int, optional): Upper bound for the number of trees. Default is 300.\n",
        "        md_low (int, optional): Lower bound for the maximum depth of the tree. Default is 3.\n",
        "        md_up (int, optional): Upper bound for the maximum depth of the tree. Default is 18.\n",
        "        colsample_bytree_low (float, optional): Lower bound for the subsample ratio of columns when constructing each tree. Default is 0.5.\n",
        "        colsample_bytree_up (float, optional): Upper bound for the subsample ratio of columns when constructing each tree. Default is 1.\n",
        "    Returns:\n",
        "        xgb_class.best_estimator_ (xgboost.sklearn.XGBClassifier): Fitted XGBoost model with the best set of hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside of XGBoost_Classifier\")\n",
        "    para = {\n",
        "        'n_estimators': np.arange(nest_low, nest_up),\n",
        "        'max_depth': np.arange(md_low, md_up+1),\n",
        "        'booster': ['gblinear', 'gbtree'],\n",
        "        'colsample_bytree': np.arange(colsample_bytree_low, colsample_bytree_up, .1),\n",
        "        'learning_rate': np.arange(lr_low, lr_up, 0.02),\n",
        "\n",
        "    }\n",
        "\n",
        "    classifier = xgb.XGBClassifier(n_jobs=6)\n",
        "    xgb_class = model_selection.RandomizedSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_distributions=para,\n",
        "        scoring=\"neg_log_loss\",\n",
        "        verbose=10,\n",
        "        n_iter=2,\n",
        "    )\n",
        "    xgb_class.fit(train.drop(labels=target, axis=1), train[target])\n",
        "    logger.info(\"end of XGBoost_Classifier\")\n",
        "    return xgb_class.best_estimator_\n",
        "\n",
        "\n",
        "def LogisticRegressionClassifier(train, test, target, penalty=['l2'], C_low=0, C_up=4):\n",
        "    \"\"\"\n",
        "    Logistic Regression Classifier function that trains a model using a randomized search cross-validation to optimize the hyperparameters of a logistic regression classifier.\n",
        "    Parameters:\n",
        "        train (pandas.DataFrame): Training data set used to fit the model.\n",
        "        test (pandas.DataFrame): Test data set used to evaluate the model.\n",
        "        target (str): Name of the target variable in the data set.\n",
        "        penalty (list, optional): List of penalty values for the logistic regression classifier. Default is ['l2'].\n",
        "        C_low (float, optional): Lower bound for the C value. Default is 0.\n",
        "        C_up (float, optional): Upper bound for the C value. Default is 4.\n",
        "    Returns:\n",
        "        lr_class.best_estimator_ (sklearn.linear_model.LogisticRegression): Fitted logistic regression model with the best set of hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside of LogisticRegressionClassifier\")\n",
        "    scale_calculated = C_up-C_low\n",
        "    eval_metric = 'neg_log_loss'\n",
        "    para = {\n",
        "        'penalty': penalty,\n",
        "        'C': uniform(loc=C_low, scale=scale_calculated)\n",
        "    }\n",
        "    classifier = LogisticRegression(n_jobs=6)\n",
        "    lr_class = model_selection.RandomizedSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_distributions=para,\n",
        "        scoring=eval_metric,\n",
        "        verbose=10,\n",
        "        n_iter=2,\n",
        "    )\n",
        "    lr_class.fit(train.drop(labels=target, axis=1).values,\n",
        "                 train[target].values)\n",
        "    logger.info(\"End of LogisticRegressionClassifier\")\n",
        "    return lr_class.best_estimator_\n",
        "\n",
        "def DecisionTreeClassifier(train, test, target, md_low=4, md_up=10, rs_low=2, rs_up=3, mln_low=3, mln_up=5, \n",
        "                           ms_low=2, ms_up=3):\n",
        "    \"\"\"\n",
        "    Perform hyperparameter tuning for a decision tree classifier using randomized search.\n",
        "\n",
        "    Parameters:\n",
        "        train (DataFrame): Training dataset.\n",
        "        test (DataFrame): Test dataset.\n",
        "        target (str): Target variable.\n",
        "        md_low (int): Lower bound of the range for the maximum depth of the decision tree. Default is 4.\n",
        "        md_up (int): Upper bound of the range for the maximum depth of the decision tree. Default is 10.\n",
        "        rs_low (int): Lower bound of the range for the random state of the decision tree. Default is 2.\n",
        "        rs_up (int): Upper bound of the range for the random state of the decision tree. Default is 3.\n",
        "        mln_low (int): Lower bound of the range for the maximum number of leaf nodes in the decision tree. Default is 3.\n",
        "        mln_up (int): Upper bound of the range for the maximum number of leaf nodes in the decision tree. Default is 5.\n",
        "        ms_low (int): Lower bound of the range for the minimum number of samples required to split an internal node in the decision tree. Default is 2.\n",
        "        ms_up (int): Upper bound of the range for the minimum number of samples required to split an internal node in the decision tree. Default is 3.\n",
        "\n",
        "    Returns:\n",
        "        DecisionTreeClassifier: The best estimator found during the hyperparameter tuning.\n",
        "    \"\"\"\n",
        " \n",
        "    logger.info(\"Inside of DecisionTreeClassifier\")\n",
        "    eval_metric = 'neg_log_loss'\n",
        "    para = {\n",
        "           \"criterion\": [\"gini\"],                  \n",
        "           \"splitter\": [\"best\"] ,                 \n",
        "           'max_depth': np.arange(md_low, md_up + 1), \n",
        "           'random_state': np.arange(rs_low, rs_up + 1),\n",
        "           'max_leaf_nodes' : np.arange(mln_low, mln_up+1) ,\n",
        "           \"min_samples_split\": np.arange(ms_low, ms_up + 1), \n",
        "        }\n",
        "    classifier = tree.DecisionTreeClassifier()  \n",
        "    lr_class = model_selection.RandomizedSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_distributions=para,\n",
        "        scoring=eval_metric,\n",
        "        verbose=10,\n",
        "        n_iter=2\n",
        "    )\n",
        "    lr_class.fit(train.drop(labels=target, axis=1).values,\n",
        "                 train[target].values)\n",
        "    logger.info(\"End of DecisionTreeClassifier\")\n",
        "    return lr_class.best_estimator_\n",
        "\n",
        "\n",
        "def perf_tune(train, test, target, model_name, hyperparameter):\n",
        "    \"\"\"\n",
        "     Tune hyperparameters of a machine learning model.\n",
        "    Args:\n",
        "        train (pandas.DataFrame): Training dataset.\n",
        "        test (pandas.DataFrame): Test dataset.\n",
        "        target (str): Name of the target variable.\n",
        "        model_name (str): Name of the model to tune.\n",
        "        hyperparameter (dict): Dictionary with hyperparameters to tune.\n",
        "    Returns:\n",
        "        hyper_m (sklearn estimator): Tuned machine learning model.\n",
        "    \"\"\"\n",
        "\n",
        "    if model_name.lower() == 'extratreesclassifierentr':\n",
        "        hyper_m = ExtraTreesClassifierEntr(train, test, target,\n",
        "                                           nest_low=hyperparameter['n_estimators'][0], nest_up=hyperparameter['n_estimators'][1],\n",
        "                                           md_low=hyperparameter['max_depth'][0], md_up=hyperparameter['max_depth'][1],\n",
        "                                           mss_low=hyperparameter['min_samples_split'][\n",
        "                                               0], mss_up=hyperparameter['min_samples_split'][1],\n",
        "                                           msl_low=hyperparameter['min_samples_leaf'][\n",
        "                                               0], msl_up=hyperparameter['min_samples_leaf'][1]\n",
        "                                           )\n",
        "\n",
        "    elif model_name.lower() == 'catboostclassifier':\n",
        "        hyper_m = catboot_hypertune(train, test, target,\n",
        "                                    lr_lower=hyperparameter['learning_rate'][0], lr_upper=hyperparameter['learning_rate'][1],\n",
        "                                    depth_low=hyperparameter['max_depth'][0], depth_upper=hyperparameter['max_depth'][1],\n",
        "                                    # mdl->iteration\n",
        "                                    mdl_low=hyperparameter['n_estimators'][0], mdl_upper=hyperparameter['n_estimators'][1],\n",
        "                                    n_low=hyperparameter['min_data_in_leaf'][0], n_upper=hyperparameter['min_data_in_leaf'][1],\n",
        "                                    cb_low=hyperparameter['colsample_bylevel'][0], cb_upper=hyperparameter['colsample_bylevel'][1]\n",
        "                                    )\n",
        "\n",
        "    elif model_name.lower() == 'extratreesclassifiergini':\n",
        "        hyper_m = ExtraTreesClassifiergini(train, test, target,\n",
        "                                           nest_low=hyperparameter['n_estimators'][0], nest_up=hyperparameter['n_estimators'][1],\n",
        "                                           md_low=hyperparameter['max_depth'][0], md_up=hyperparameter['max_depth'][1],\n",
        "                                           mss_low=hyperparameter['min_samples_split'][\n",
        "                                               0], mss_up=hyperparameter['min_samples_split'][1],\n",
        "                                           msl_low=hyperparameter['min_samples_leaf'][\n",
        "                                               0], msl_up=hyperparameter['min_samples_leaf'][1]\n",
        "                                           )\n",
        "\n",
        "    elif model_name.lower() == 'randomforestclassifierentr':\n",
        "        hyper_m = RandomForestClassifierEntr(train, test, target,\n",
        "                                             nest_low=hyperparameter['n_estimators'][0], nest_up=hyperparameter['n_estimators'][1],\n",
        "                                             md_low=hyperparameter['max_depth'][0], md_up=hyperparameter['max_depth'][1],\n",
        "                                             mss_low=hyperparameter['min_samples_split'][\n",
        "                                                 0], mss_up=hyperparameter['min_samples_split'][1],\n",
        "                                             msl_low=hyperparameter['min_samples_leaf'][\n",
        "                                                 0], msl_up=hyperparameter['min_samples_leaf'][1]\n",
        "                                             )\n",
        "\n",
        "    elif model_name.lower() == 'randomforestclassifiergini':\n",
        "        hyper_m = RandomForestClassifiergini(train, test, target,\n",
        "                                             nest_low=hyperparameter['n_estimators'][0], nest_up=hyperparameter['n_estimators'][1],\n",
        "                                             md_low=hyperparameter['max_depth'][0], md_up=hyperparameter['max_depth'][1],\n",
        "                                             mss_low=hyperparameter['min_samples_split'][\n",
        "                                                 0], mss_up=hyperparameter['min_samples_split'][1],\n",
        "                                             msl_low=hyperparameter['min_samples_leaf'][\n",
        "                                                 0], msl_up=hyperparameter['min_samples_leaf'][1]\n",
        "                                             )\n",
        "\n",
        "    elif model_name.lower() == 'kneighborsclassifierdist':\n",
        "        hyper_m = KNeighborsClassifierDist(train, test, target,\n",
        "                                           nj_low=hyperparameter['n_jobs'][0], nj_up=hyperparameter['n_jobs'][1],\n",
        "                                           n_neighbors_low=hyperparameter['n_neighbors'][\n",
        "                                               0], n_neighbors_up=hyperparameter['n_neighbors'][1]\n",
        "                                           )\n",
        "\n",
        "    elif model_name.lower() == 'kneighborsclassifierunif':\n",
        "        hyper_m = KNeighborsClassifierunif(train, test, target,\n",
        "                                           nj_low=hyperparameter['n_jobs'][0], nj_up=hyperparameter['n_jobs'][1],\n",
        "                                           n_neighbors_low=hyperparameter['n_neighbors'][\n",
        "                                               0], n_neighbors_up=hyperparameter['n_neighbors'][1]\n",
        "                                           )\n",
        "\n",
        "    elif model_name.lower() == 'xgboost_classifier':\n",
        "        hyper_m = XGBoost_Classifier(train, test, target,\n",
        "                                     lr_low=hyperparameter['learning_rate'][0], lr_up=hyperparameter['learning_rate'][1],\n",
        "                                     nest_low=hyperparameter['n_estimators'][0], nest_up=hyperparameter['n_estimators'][1],\n",
        "                                     md_low=hyperparameter['max_depth'][0], md_up=hyperparameter['max_depth'][1],\n",
        "                                     colsample_bytree_low=0, colsample_bytree_up=1)\n",
        "\n",
        "    elif model_name.lower() == 'logisticregressionclassifier':\n",
        "        hyper_m = LogisticRegressionClassifier(train, test, target,\n",
        "                                               penalty=['l2'],\n",
        "                                               C_low=hyperparameter['C'][0],\n",
        "                                               C_up=hyperparameter['C'][1])\n",
        "        \n",
        "    elif model_name.lower() == 'decisiontreeclassifier':\n",
        "        hyper_m = DecisionTreeClassifier(train, test, target, md_low=hyperparameter['max_depth'][0],\n",
        "                                        md_up=hyperparameter['max_depth'][1],rs_low=hyperparameter['random_state'][0],\n",
        "                                        rs_up=hyperparameter['random_state'][1], mln_low=hyperparameter['max_leaf_nodes'][0],\n",
        "                                        mln_up=hyperparameter['max_leaf_nodes'][1], ms_low=hyperparameter['min_samples_split'][0],\n",
        "                                        ms_up=hyperparameter['min_samples_split'][1])\n",
        "\n",
        "    logger.info(\"End of Hyper Tune Function\")\n",
        "    return hyper_m\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    \"\"\"\n",
        "    A function to generate a heatmap of the confusion matrix for binary classification models.\n",
        "    The function takes the true labels and predicted labels for a binary classification model and \n",
        "    generates a heatmap of the confusion matrix using Plotly. \n",
        "    The class names can be optionally provided as a list of strings. \n",
        "    The function returns the heatmap figure and a dictionary containing information about the chart title and type.\n",
        "    Args:\n",
        "        y_true (array-like): The true labels for the binary classification model.\n",
        "        y_pred (array-like): The predicted labels for the binary classification model.\n",
        "        class_names (list, optional): A list of strings containing the names of the two classes. \n",
        "        Defaults to ['Positive', 'Negative'].\n",
        "    Returns:\n",
        "        tuple: A tuple containing the Plotly heatmap figure and\n",
        "        a dictionary with information about the chart title and type.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside plot_confusion_matrix\")\n",
        "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
        "    confusion_matrix = confusion_matrix.astype(int)\n",
        "\n",
        "    x = ['Negative (0)','Positive (1)']\n",
        "    y = ['Negative (0)','Positive (1)']\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for step in range(9):\n",
        "        fig.add_trace(\n",
        "            go.Heatmap(visible=False, x=x, y=y, xgap=2, ygap=2,z=confusion_matrix, colorscale=[\n",
        "                       [0, 'rgb(174, 205, 252)'], [1, 'rgb(39, 45, 85)']])\n",
        "        )\n",
        "    fig.update_traces(dict(showscale=True))\n",
        "    fig.data[4].visible = True\n",
        "    fig.update_yaxes(title='Actual value')\n",
        "    fig.update_xaxes(title='Predicted value',side='bottom')\n",
        "    anno2 = []\n",
        "    for i, row in enumerate(confusion_matrix):\n",
        "        for j, value2 in enumerate(row):\n",
        "            anno2.append(\n",
        "                {\n",
        "                    \"x\": x[j],\n",
        "                    \"y\": y[i],\n",
        "                    \"font\": {\"color\": \"white\", \"size\": 16},\n",
        "                    \"text\": str(value2),\n",
        "                    \"xref\": \"x1\",\n",
        "                    \"yref\": \"y1\",\n",
        "                    \"showarrow\": False,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    # Create and add slider\n",
        "    steps = []\n",
        "    for i in range(len(fig.data)):\n",
        "        step = dict(\n",
        "            method=\"update\",\n",
        "            args=[\n",
        "                {\"visible\": [False] * len(fig.data)},\n",
        "                {\"title\": \"Slider Switched To Threshold: \" +\n",
        "                    str((i + 1) / 10)},\n",
        "            ],\n",
        "            label=\"Threshold : \" + str((i + 1) / 10),  # layout attribute\n",
        "        )\n",
        "        step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
        "        steps.append(step)\n",
        "\n",
        "    sliders = [\n",
        "        dict(active=10, currentvalue={\n",
        "             \"prefix\": \" \"}, pad={\"t\": 10}, steps=steps)\n",
        "    ]\n",
        "\n",
        "    fig.update_layout(\n",
        "        title_text=f\"CONFUSION MATRIX\", title_x=0.5, annotations=anno2\n",
        "    )\n",
        "    title = {\"title\": \"Confusion Matrix\",\n",
        "             \"chart_type\": \"Plot_confusion_matrix\"}\n",
        "    logger.info(\"END of plot_confusion_matrix\")\n",
        "    return fig, title\n",
        "\n",
        "\n",
        "def draw_ks_statistic(thresholds, ks_statistic, max_distance_at, pct1, pct2):\n",
        "    \"\"\"\n",
        "    Draws the Kolmogorov-Smirnov (KS) statistic plot for a binary classification model.\n",
        "    Args:\n",
        "        thresholds: A 1D array of threshold values.\n",
        "        ks_statistic: A float representing the maximum distance between the two empirical cumulative distribution functions (ECDFs).\n",
        "        max_distance_at: A float representing the threshold value at which the maximum distance occurs.\n",
        "        pct1: A 1D array representing the percentage of Class 0 predictions below each threshold value.\n",
        "        pct2: A 1D array representing the percentage of Class 1 predictions below each threshold value.\n",
        "    Returns:\n",
        "        fig: A plotly figure object representing the KS statistic plot.\n",
        "        title: A dictionary containing information about the plot.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside draw_ks_statistic\")\n",
        "    fig = go.Figure()\n",
        "    count_data = len(pct1)\n",
        "    if count_data > 100000:\n",
        "        step_ann = math.ceil(count_data/100000)\n",
        "        pct1 = pct1[::step_ann]\n",
        "        pct2 = pct2[::step_ann]\n",
        "        thresholds = thresholds[::step_ann]\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=thresholds, y=pct2,\n",
        "                             mode='lines',\n",
        "                             name='Class 1',\n",
        "                             line=dict(color='#272D55')))\n",
        "    fig.add_trace(go.Scatter(x=thresholds, y=pct1,\n",
        "                             mode='lines',\n",
        "                             name='Class 0',\n",
        "                             line=dict(color=\"#aecdfc\")))\n",
        "    fig.add_annotation(\n",
        "        x=1,\n",
        "        y=0.05,\n",
        "        showarrow=False,\n",
        "        text='KS Statistic : {:.3f} at {:.3f}'.format(ks_statistic,\n",
        "                                                      max_distance_at),\n",
        "        font=dict(\n",
        "        family='\"Open Sans\"',\n",
        "        size=12,\n",
        "        color='black'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=\"KS Statistic\",\n",
        "        yaxis_title=\"Percentage Below Threshold\",\n",
        "        xaxis_title=\"Threshold\",\n",
        "        font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=1,\n",
        "            color=\"#7f7f7f\"\n",
        "        )\n",
        "    )\n",
        "    fig.update_layout({'plot_bgcolor': 'rgba(0,0,0,0)',\n",
        "                      'paper_bgcolor': 'rgba(0,0,0,0)'})\n",
        "    fig.update_xaxes(title_text='threshold',\n",
        "                     title_font=dict(family=\"Courier New, monospace\", size=18, color='#7f7f7f'))\n",
        "    fig.update_yaxes(title_text=' Percentage Below Threshold ', title_font_size=18,\n",
        "                     title_font_family=\"Courier New, monospace\", title_font_color=\"#7f7f7f\")\n",
        "    fig.update_xaxes(showline=True, linewidth=4, linecolor='black')\n",
        "    fig.update_yaxes(showline=True, linewidth=4, linecolor='black')\n",
        "    title = {\"title\": \"KS Statistic\", \"chart_type\": \"Plot_ks_statistic\"}\n",
        "    logger.info(\"End of draw_ks_statistic\")\n",
        "    return fig, title\n",
        "\n",
        "\n",
        "def plot_ks_statistic(y_true, y_probas, title='KS Statistic Plot'):\n",
        "    logger.info(\"Inside plot_ks_statistic\")\n",
        "    y_true = np.array(y_true)\n",
        "    y_probas = np.array(y_probas)\n",
        "\n",
        "    classes = np.unique(y_true)\n",
        "    if len(classes) != 2:\n",
        "        raise ValueError('Cannot calculate KS statistic for data with '\n",
        "                         '{} category/ies'.format(len(classes)))\n",
        "    probas = y_probas\n",
        "\n",
        "    thresholds, pct1, pct2, ks_statistic, \\\n",
        "        max_distance_at, classes = binary_ks_curve(y_true,\n",
        "                                                   probas[:, 1].ravel())\n",
        "    logger.info(\"End of plot_ks_statistic\")\n",
        "\n",
        "    return draw_ks_statistic(thresholds, ks_statistic, max_distance_at, pct1, pct2)\n",
        "\n",
        "\n",
        "def draw_lift_curve(percentages, gains1, gains2):\n",
        "    \"\"\"\n",
        "    This function generates a plot for Lift Curve. The Lift curve is a graphical representation of the improvement\n",
        "    that a classification model provides over random guess. \n",
        "    The x-axis represents the percentage of the sample, while the y-axis represents the Lift.\n",
        "    Args:\n",
        "\n",
        "        percentages: A 1D array of percentages of the sample.\n",
        "        gains1: A 1D array of gains for Class 0.\n",
        "        gains2: A 1D array of gains for Class 1.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "        fig: A plotly figure object representing the Lift Curve.\n",
        "        title: A dictionary containing information about the plot.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside draw_lift_curve\")\n",
        "    fig = go.Figure()\n",
        "\n",
        "    count_data = len(gains1)\n",
        "    if count_data > 100000:\n",
        "        step_ann = math.ceil(count_data/100000)\n",
        "        gains1 = gains1[::step_ann]\n",
        "        gains2 = gains2[::step_ann]\n",
        "        percentages = percentages[::step_ann]\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=percentages, y=gains1,\n",
        "                             mode='lines',\n",
        "                             name='Class 0',\n",
        "                             line=dict(color='#272D55')))\n",
        "    fig.add_trace(go.Scatter(x=percentages, y=gains2,\n",
        "                             mode='lines',\n",
        "                             name='Class 1',\n",
        "                             line=dict(color=\"#aecdfc\")))\n",
        "    fig.add_trace(go.Scatter(x=[0, 1], y=[1, 1],\n",
        "                             mode='lines',\n",
        "                             name='Baseline',\n",
        "                             line=dict(color='black', dash='dash')))\n",
        "    fig.update_layout(\n",
        "        title=\"Lift Curve\",\n",
        "        yaxis_title=\"Lift\",\n",
        "        xaxis_title=\"Percentage Of Sample\",\n",
        "        font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=18,\n",
        "            color=\"#7f7f7f\"))\n",
        "    fig.update_layout({'plot_bgcolor': 'rgba(0,0,0,0)',\n",
        "                      'paper_bgcolor': 'rgba(0,0,0,0)'})\n",
        "    fig.update_xaxes(title_text='Percentage Of Sample',\n",
        "                     title_font=dict(family=\"Courier New, monospace\", size=18, color='#7f7f7f'))\n",
        "    fig.update_yaxes(title_text=' Gain', title_font_size=18, title_font_family=\"Courier New, monospace\",\n",
        "                     title_font_color=\"#7f7f7f\")\n",
        "    fig.update_xaxes(showline=True, linewidth=4, linecolor='black')\n",
        "    fig.update_yaxes(showline=True, linewidth=4, linecolor='black')\n",
        "    title = {\"title\": \"Lift Curve\", \"chart_type\": \"Precision_r\"}\n",
        "    logger.info(\"End draw_lift_curve\")\n",
        "    return fig, title\n",
        "\n",
        "\n",
        "def plot_lift_curve(y_true, y_probas):\n",
        "    \"\"\"\n",
        "    Plots the Lift Curve for binary classification models.\n",
        "    Args:\n",
        "        y_true (array-like): Array of true labels.\n",
        "        y_probas (array-like): Array of predicted probabilities for each class.\n",
        "    Returns:\n",
        "        A tuple containing the lift curve plot and a dictionary with title and chart type.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside plot_lift_curve\")\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_probas = np.array(y_probas)\n",
        "\n",
        "    classes = np.unique(y_true)\n",
        "    if len(classes) != 2:\n",
        "        raise ValueError('Cannot calculate Lift Curve for data with '\n",
        "                         '{} category/ies'.format(len(classes)))\n",
        "\n",
        "    # Compute Cumulative Gain Curves\n",
        "    percentages, gains1 = cumulative_gain_curve(y_true, y_probas[:, 0],\n",
        "                                                classes[0])\n",
        "    percentages, gains2 = cumulative_gain_curve(y_true, y_probas[:, 1],\n",
        "                                                classes[1])\n",
        "\n",
        "    percentages = percentages[1:]\n",
        "    gains1 = gains1[1:]\n",
        "    gains2 = gains2[1:]\n",
        "\n",
        "    gains1 = gains1 / percentages\n",
        "    gains2 = gains2 / percentages\n",
        "\n",
        "    logger.info(\"end plot_lift_curve\")\n",
        "    return draw_lift_curve(percentages, gains1, gains2)\n",
        "\n",
        "\n",
        "def precision_r(y, y_score):\n",
        "    \"\"\"\n",
        "     Computes the Precision-Recall curve and returns a Plotly figure object.\n",
        "    Args:\n",
        "        y: array-like of shape (n_samples,), true binary labels.\n",
        "        y_score: array-like of shape (n_samples,), scores of the positive class.\n",
        "    Returns:\n",
        "        fig: Plotly figure object representing the Precision-Recall curve.\n",
        "        title: dictionary containing the title of the chart and its type.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside precision_r\")\n",
        "    fpr, tpr, thresholds = roc_curve(y, y_score)\n",
        "    precision, recall, thresholds = precision_recall_curve(y, y_score)\n",
        "    fig = go.Figure()\n",
        "\n",
        "    count_data = len(fpr)\n",
        "    if count_data > 100000:\n",
        "        step_ann = math.ceil(count_data/100000)\n",
        "        fpr = fpr[::step_ann]\n",
        "        tpr = tpr[::step_ann]\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=recall, y=precision,\n",
        "\n",
        "                             mode='lines',\n",
        "                             line_color='#AECDFC',\n",
        "\n",
        "                             ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n",
        "\n",
        "        font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=18,\n",
        "            color=\"#000000\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "    fig.update_xaxes(constrain='domain')\n",
        "    fig.update_xaxes(title_text='Recall',\n",
        "                     title_font=dict(family=\"Courier New, monospace\", size=18, color='#7f7f7f'))\n",
        "    fig.update_yaxes(title_text=' Precision ', title_font_size=18,\n",
        "                     title_font_family=\"Courier New, monospace\", title_font_color=\"#7f7f7f\")\n",
        "\n",
        "    fig.update_layout({'plot_bgcolor': 'rgba(0,0,0,0)',\n",
        "                      'paper_bgcolor': 'rgba(0,0,0,0)'})\n",
        "\n",
        "    fig.update_xaxes(showline=True, linewidth=4, linecolor='black')\n",
        "    fig.update_yaxes(showline=True, linewidth=4, linecolor='black')\n",
        "    title_str = f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})'\n",
        "    title = {\"title\": title_str, \"chart_type\": \"Precision_r\"}\n",
        "    logger.info(\"end precision_r\")\n",
        "    return fig, title\n",
        "\n",
        "\n",
        "def roc(y_true, y_score):\n",
        "    \"\"\"Compute ROC curve and ROC area for each class\n",
        "    Args:\n",
        "        y_true: true labels\n",
        "        y_score: predicted labels\n",
        "    \"\"\"\n",
        "    logger.info(\"Insdie roc\")\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    count_data = len(fpr)\n",
        "    if count_data > 100000:\n",
        "        step_ann = math.ceil(count_data/100000)\n",
        "        fpr = fpr[::step_ann]\n",
        "        tpr = tpr[::step_ann]\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=fpr, y=tpr,\n",
        "                             mode='lines',\n",
        "\n",
        "                             line=dict(color='#AECDFC'),\n",
        "                             )\n",
        "                  )\n",
        "    fig.add_trace(go.Scatter(x=[0,1], y=[0,1],\n",
        "                             mode='lines',\n",
        "                             name=\"No-skill\",\n",
        "\n",
        "                             line=dict(color='#222222', dash='dash')\n",
        "                             )\n",
        "                  )\n",
        "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "    fig.update_xaxes(constrain='domain')\n",
        "    fig.update_layout(\n",
        "        title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
        "\n",
        "        font=dict(\n",
        "            family=\"Courier New, monospace\",\n",
        "            size=18,\n",
        "            color=\"#7f7f7f\"\n",
        "        )\n",
        "    )\n",
        "    fig.update_layout({'plot_bgcolor': 'rgba(0,0,0,0)',\n",
        "                      'paper_bgcolor': 'rgba(0,0,0,0)'})\n",
        "    fig.update_xaxes(title_text='False Positive Rate',\n",
        "                     title_font=dict(family=\"Courier New, monospace\", size=18, color='#7f7f7f'))\n",
        "    fig.update_yaxes(title_text=' True Positive Rate ', title_font_size=18,\n",
        "                     title_font_family=\"Courier New, monospace\", title_font_color=\"#7f7f7f\")\n",
        "    fig.update_xaxes(showline=True, linewidth=4, linecolor='black')\n",
        "    fig.update_yaxes(showline=True, linewidth=4, linecolor='black')\n",
        "    title_str = f'ROC Curve (AUC={auc(fpr, tpr):.4f})'\n",
        "    title = {\"title\": title_str, \"chart_type\": \"Roc\"}\n",
        "    logger.info(\"end roc\")\n",
        "    return fig, title\n",
        "\n",
        "\n",
        "def callibration(data, target, model_name, hyperparameter,task_id=None):\n",
        "    \"\"\"Calibrates a classification model using the specified hyperparameters and evaluates its performance on a test set.\n",
        "    Args:\n",
        "        data (pandas.DataFrame): The dataset to be used for model calibration and evaluation.\n",
        "        target (str): The name of the column in `data` that contains the target variable.\n",
        "        model_name (str): The name of the classification model to be calibrated (e.g., 'LogisticRegression', 'RandomForestClassifier').\n",
        "        hyperparameter (dict): A dictionary of hyperparameters to be used for model calibration.\n",
        "    Returns:\n",
        "        tuple: A tuple containing five figures and their corresponding titles representing the model's performance\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(\"Inside main function\")\n",
        "    train, test = model_selection.train_test_split(\n",
        "        data, test_size=0.3, random_state=48)\n",
        "    hyper_model = perf_tune(train, test, target, model_name, hyperparameter)\n",
        "    logger.info(\"hyper model selection\")\n",
        "    y_true = test[target].values\n",
        "    y_pred = hyper_model.predict(test.drop(labels=target, axis=1))\n",
        "    y_probas = hyper_model.predict_proba(test.drop(labels=target, axis=1))\n",
        "    y_score = y_probas[:, 1]\n",
        "\n",
        "    cn = data[target].unique()\n",
        "\n",
        "    fig1, title1 = plot_confusion_matrix(y_true, y_pred, cn)\n",
        "\n",
        "    fig2, title2 = roc(y_true, y_score)\n",
        "\n",
        "    fig3, title3 = plot_ks_statistic(test[target].values, y_probas)\n",
        "\n",
        "    progress_bar_update(task_id, percent_progress=50)\n",
        "\n",
        "    fig4, title4 = precision_r(test[target].values, y_score)\n",
        "\n",
        "    fig5, title5 = plot_lift_curve(test[target].values, y_probas)\n",
        "    figures = (fig1, fig2, fig3, fig4, fig5)\n",
        "    titles = (title1, title2, title3, title4, title5)\n",
        "    logger.info(\"after figure in main function\")\n",
        "\n",
        "    def confusionMatrix(y, pred):\n",
        "        return confusion_matrix(y, pred)\n",
        "\n",
        "    def specificity(y, pred):\n",
        "        cm = confusionMatrix(y, pred)\n",
        "        return cm[0, 0]/(cm[0, 0]+cm[0, 1])\n",
        "\n",
        "    def sensitivity(y, pred):\n",
        "        cm = confusionMatrix(y, pred)\n",
        "        return cm[1, 1]/(cm[1, 0]+cm[1, 1])\n",
        "\n",
        "    def f1Score(y, pred):\n",
        "        return f1_score(y, pred)\n",
        "\n",
        "    def precision(y, pred):\n",
        "        return precision_score(y, pred)\n",
        "\n",
        "    def recall(y, pred):\n",
        "        return recall_score(y, pred)\n",
        "\n",
        "    def logLoss(y, pred):\n",
        "        return log_loss(y, pred)\n",
        "\n",
        "    def rocAUC(yTrue, prob):\n",
        "        rocaucScore = roc_auc_score(yTrue, prob)\n",
        "        fpr, tpr, _ = roc_curve(yTrue, prob)\n",
        "        return rocaucScore\n",
        "\n",
        "    def gini(yTrue, prob):\n",
        "        return (2*rocAUC(yTrue, prob))-1\n",
        "\n",
        "    metrics_dict = {\n",
        "        \"ACCURACY\": sklearn.metrics.accuracy_score(y_true, y_pred),\n",
        "        \"SENSITIVITY\": sensitivity(y_true, y_pred),\n",
        "        \"SPECIFICITY\": specificity(y_true, y_pred),\n",
        "        \"F1_SCORE\": f1Score(y_true, y_pred),\n",
        "        \"PRECISION\": precision(y_true, y_pred),\n",
        "        \"RECALL\": recall(y_true, y_pred),\n",
        "        \"LOGLOSS\": logLoss(y_true, y_pred),\n",
        "        \"rocAUC_score\": rocAUC(y_true, y_pred),\n",
        "        \"gini\": gini(y_true, y_pred)\n",
        "    }\n",
        "    logger.info(\"after metrics in main function\")\n",
        "    final_metrics = pd.DataFrame(list(metrics_dict.items()), columns=[\n",
        "                                 'Metrics', 'Score']).round(2)\n",
        "    progress_bar_update(task_id, percent_progress=80)\n",
        "    return hyper_model, final_metrics, figures, titles\n",
        "\n",
        "\n",
        "def recalibrate_execution(args):\n",
        "    \"\"\"\n",
        "    This function recalibrates a given model with the given hyperparameters and saves the recalibrated model,\n",
        "    metrics, charts,and title to S3. It also sends a message to an internal queue \n",
        "    indicating the completion status of the recalibration process.\n",
        "    \"\"\"\n",
        "\n",
        "    task_id = args[\"task_id\"]\n",
        "    DType = args[\"Dtype\"]\n",
        "    user_ = args[\"username\"]\n",
        "    start_time = datetime.now()\n",
        "    logger.info(\n",
        "        f\"callibration - Task ID : {task_id} , User : {user_} Started in Worker at time {start_time}\")\n",
        "    try:\n",
        "        data = read_para(task_id, DType, user_)\n",
        "\n",
        "        isFolder = data['isFolder']\n",
        "\n",
        "        target = data[\"target_column\"]\n",
        "        user = data[\"user\"]\n",
        "\n",
        "        helper = Helper()\n",
        "        data_key = data[\"table_data_key\"]\n",
        "        df = fetch_data_as_df(data_key[\"location\"], data_key[\"dataset\"])\n",
        "        logger.info(\"After fetch data\")\n",
        "        df = helper.drop_pk(df)\n",
        "\n",
        "        progress_bar_update(task_id, percent_progress=20)\n",
        "\n",
        "        call_model, metrics, graphs, title = callibration(\n",
        "            df, target, data[\"modelname\"], data[\"hyperparameter\"],task_id=task_id\n",
        "        )\n",
        "        logger.info(\"After main function execution\")\n",
        "        location = f\"NimbusFileManagement/NimbusUsers/{DType}/{user_}\"\n",
        "       \n",
        "\n",
        "        ''' \n",
        "        \n",
        "        --> jsonpickle is a Python library for serialization and deserialization of complex Python objects to and from JSON. \n",
        "        --> The standard Python libraries for encoding Python into JSON can only handle Python primitives that have a direct \n",
        "            JSON equivalent (e.g. dicts, lists, strings, ints, etc.). \n",
        "        --> jsonpickle builds on top of these libraries and allows more complex data structures to be serialized to JSON.\n",
        "\n",
        "        '''\n",
        "        call_model_json = jsonpickle.encode(call_model)\n",
        "        call_model_dict = {}\n",
        "        call_model_dict[\"call_model\"] = call_model_json\n",
        "\n",
        "        key_modal = f\"{location}/Charts/MpCharts/{task_id}_modal.json\"\n",
        "        store.put_object(key=key_modal,\n",
        "                      data=json.dumps(call_model_dict),\n",
        "                      container_name=BUCKET_NAME)\n",
        "        logger.info(\"key_modal json\")\n",
        "        metrics = metrics.to_dict(\"records\")\n",
        "        table_dict = {}\n",
        "        table_dict[\"table\"] = metrics\n",
        "\n",
        "        key_table = f\"{location}/Charts/MpCharts/{task_id}_table.json\"\n",
        "\n",
        "        store.put_object(key=key_table,\n",
        "                      data=json.dumps(table_dict),\n",
        "                      container_name=BUCKET_NAME)\n",
        "        logger.info(\"key_table json\")\n",
        "        chart_ids = data.get(\"chart_ids\", [])\n",
        "        i = 0\n",
        "        key_ = []\n",
        "        for fig in graphs:\n",
        "            _fig = update_chart_html(fig, chart_ids[i], data['static_chart'])\n",
        "            hkey = save_chart_to_s3(\n",
        "                chart_id=chart_ids[i], fig=_fig, base=location)\n",
        "            i = i+1\n",
        "            key_.append(hkey)\n",
        "\n",
        "        charts = {\n",
        "            \"id\": chart_ids,\n",
        "            \"title\": title,\n",
        "            \"key\": key_,\n",
        "        }\n",
        "    \n",
        "\n",
        "        message = {\"task_id\": task_id, \"operation\": \"Recalibrate\",\n",
        "                   \"Dtype\": DType, \"username\": user_, \"charts\": charts}\n",
        "        message_ = json.dumps(message)\n",
        "\n",
        "        send_msg_to_sqs(message_)\n",
        "        \n",
        "        logger.info(\n",
        "            f'Message : {message_} to Queue {InternalQueue} from Worker to Django')\n",
        "        end_time = datetime.now()\n",
        "        logger.info(\n",
        "            f\"start Time: {start_time}, end Time: {end_time}, Total Time Taken : {end_time-start_time}\")\n",
        "        logger.info(\n",
        "            f\" callibration - Task ID : {task_id} , User : {user_} Completed in Worker With Execution time {end_time-start_time}\")\n",
        "       \n",
        "    except Exception as ex:\n",
        "        tr = traceback.format_exc()\n",
        "        logger.error(tr)\n",
        "        logger.info(\n",
        "            f\" callibration - Task ID : {task_id} , User : {user_} Failed in Worker with error {str(ex)}\")\n",
        "\n",
        "        message = {\"task_id\": task_id, \"Error\": str(\n",
        "            ex), \"operation\": \"Failed\", \"type_\": \"Scoring\", \"submodule\": \"scoring/scaling\", \"Dtype\": DType, \"username\": user_}\n",
        "        message_ = json.dumps(message)\n",
        "        \n",
        "        logger.error(\n",
        "            f'Message : {message_} to Queue {InternalQueue} from Worker to Django')\n",
        "        send_msg_to_sqs(message_)"
      ],
      "metadata": {
        "id": "kLYaieViBlSJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}